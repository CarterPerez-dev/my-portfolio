{
  "slug": "cisa-presidents-cup-ctf",
  "language": "en",
  "title": "CISA President's Cup CTF Platform",
  "subtitle": "Distributed CTF platform backend with real-time scoring and multi-container WebSocket coordination",
  "description": "Core backend contributor for CISA's annual President's Cup cybersecurity competition platform. Designed and implemented the foundational architecture including real-time notification system, scoring engine, support ticketing, and the middleware patterns adopted across the codebase. The platform handles concurrent users across distributed Flask containers in a Docker Swarm deployment.",
  "technical_details": "## The Distributed Coordination Problem\n\nThe platform runs multiple Flask containers behind a load balancer. Standard WebSocket implementations break in this setup because Flask-SocketIO rooms are in-memory per process. If User A connects to Container 1 and User B connects to Container 2, they can't communicate through rooms. Every real-time feature (leaderboard updates, scoring notifications, support ticket replies) needed a solution that worked across container boundaries.\n\n## Redis Pub/Sub as the Coordination Layer\n\nThe solution: each container maintains its own lookup table mapping user IDs to socket session IDs. When a notification fires, it publishes to a Redis channel. Every container receives the message, checks \"is this user connected to me?\", and only emits if they have an active connection. No wasted broadcasts, no cross-container room management.\n\n```python\ndef _handle_notification_message(self, message):\n    user_ids = message.get('user_ids', [])\n    event_name = message.get('event_name')\n    data = message.get('data')\n\n    for user_id in user_ids:\n        user_sids = get_user_connections(user_id)  # Local lookup only\n        for sid in user_sids:\n            self.socketio.emit(event_name, data, to=sid)\n```\n\nThe `user_connections` dict is per-container. Redis handles the broadcast, each container handles its own users. Clean separation.\n\n## The Gunicorn Threading Bug\n\nIn development, everything worked. In production with Gunicorn's gevent workers, the Redis subscriber thread would silently die. Two compounding issues: Gunicorn's pre-fork model destroys threads started during app initialization, and gevent's monkey patching timing differs between dev and prod. The fix was replacing `threading.Thread` with `socketio.start_background_task()`, which auto-selects `gevent.spawn()` in gevent mode. Small change, hours of debugging to find it.\n\n## Abstracting the Complexity\n\nDomain code shouldn't know about Redis or container coordination. The `NotificationService` exposes simple methods like `broadcast_attempt_update(event_id, team_id, challenge_id)`. Under the hood it resolves user IDs, publishes to Redis, handles failures gracefully. A teammate working on the scoring controller just calls the method and moves on.\n\n```python\n@staticmethod\ndef broadcast_attempt_update(event_id, team_id, challenge_id, question_id):\n    NotificationService._emit_refetch(\n        path=f\"/ng/events/{event_id}/challenges/{challenge_id}\",\n        team_id=team_id\n    )\n    NotificationService._emit_refetch(\n        path=f\"/ng/events/{event_id}/leaderboard\",\n        event_id=event_id\n    )\n```\n\n## Decorator-Based Middleware\n\nEvery endpoint needs auth, input validation, resource loading, and permission checks. Writing that boilerplate in every route handler is error-prone and ugly. The approach that emerged (through a lot of PR feedback and iteration with the team): composable decorators that stack cleanly.\n\n```python\n@user_endpoint(json_required=True)\n@load_event(LoaderType.PARAM)\n@load_challenge(LoaderType.PARAM)\n@load_question(LoaderType.PARAM)\n@load_team_by_user_and_event()\n@check_permissions(PermissionEnum.CAN_PLAY_CHALLENGES)\ndef post(self, event_id, challenge_id, question_id,\n         event, challenge, question, team, current_user, json_data):\n    return submit_answer(event, challenge, question, team, current_user, json_data)\n```\n\nBy the time the handler runs, auth is verified, JSON is parsed, all models are loaded, permissions are checked. The handler just does business logic. This pattern spread across the entire backend. Resource loaders for events, teams, tickets, scores. Permission decorators. Ownership validators. All composable.\n\n## Validation Framework\n\nEvery model needs input validation with consistent error messages. Instead of ad-hoc checks scattered through controllers, there's a `BaseValidator` with chainable methods and a `@validation_field` decorator that handles the common patterns (required checks, None handling, friendly error messages).\n\n```python\nvalidator = BaseValidator()\nvalidator.validate_string(data, \"name\", max_length=64, required=True)\nvalidator.validate_model_id(data, \"event_id\", \"Event\", required=True)\nvalidator.validate_datetime(data, \"expires_at\", allow_past=False)\nreturn validator.validate()  # Returns clean dict or raises ValidationError\n```\n\nSingle pass: validates and extracts parsed data. Every model's `validate()` classmethod uses this. Consistent error shape across the entire API.\n\n## What I Learned\n\nThis was my first time working on something at this scale with a real team. The senior devs on the project (particularly the ones handling DevOps, the complex Docker Swarm orchestration, challenge parsing, VNC management, and more) taught me how to actually think about distributed systems, not just build features. The decorator patterns came out of code review feedback. The validation framework evolved through multiple iterations based on what the team actually needed. Looking at my early PRs versus the later ones, the growth is embarrassing but real. Shipping code that other people have to maintain changes how you write it.",
  "tech_stack": ["Python", "Flask", "Flask-SocketIO", "Redis", "PostgreSQL", "SQLAlchemy", "AWS SES", "AWS S3", "CTFd", "Docker Swarm", "pytest", "Nginx"],
  "github_url": "https://github.com/CyberSkyline/ctf-ng",
  "website_url": "https://presidentscup.cisa.gov/",
  "demo_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": null,
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": "@user_endpoint(json_required=True)\n@load_event(LoaderType.PARAM)\n@load_challenge(LoaderType.PARAM)\n@load_question(LoaderType.PARAM)\n@load_team_by_user_and_event()\n@limiter.limit(\"1 per 1 seconds\")\n@check_permissions(PermissionEnum.CAN_PLAY_CHALLENGES, \"You do not have permission to play challenges.\")\ndef post(\n    self,\n    event_id: int,\n    challenge_id: int,\n    question_id: int,\n    event,\n    challenge,\n    question,\n    team,\n    current_user: User,\n    permissions,\n    json_data,\n    **kwargs,\n):\n    result = submit_answer(\n        event=event,\n        challenge=challenge,\n        question=question,\n        team=team,\n        current_user=current_user,\n        submission=json_data.get(\"submission\", \"\"),\n    )\n    return success_response(result, status_code=201)",
  "code_language": "python",
  "code_filename": "https://github.com/CyberSkyline/ctf-ng/blob/development/backend/ng/scoring/routes/user_routes.py",
  "display_order": 0,
  "is_complete": true,
  "is_featured": true,
  "thumbnail_url": null,
  "banner_url": null,
  "screenshots": null,
  "stars_count": 3,
  "forks_count": null,
  "downloads_count": null,
  "users_count": null,
  "status": "active",
  "start_date": "2025-05-01",
  "end_date": null
}
