{
  "slug": "fastapi-rc",
  "language": "es",
  "title": "fastapi-rc",
  "subtitle": "Redis caching para FastAPI sin la magia de decoradores",
  "description": "Una librería de caching Redis de tres niveles para FastAPI que te da acceso directo al cliente, un wrapper de servicio genérico, y caches de dominio personalizados que se integran con la inyección de dependencias de FastAPI. Construida para desarrolladores que quieren control granular sobre el comportamiento del cache en lugar de decoradores con opiniones fuertes.",
  "technical_details": "La librería está estructurada alrededor de tres niveles de abstracción que puedes mezclar libremente. En el fondo, obtienes el cliente Redis async raw a través del sistema de DI de FastAPI. Una capa arriba, CacheService envuelve patrones comunes como cache-aside, gestión de TTL y serialización. En la cima, defines caches tipados por dominio como dependencias. Esto te permite bajar a Redis raw para pipelines o scripts Lua mientras usas la capa de servicio para el 90% de las operaciones.\n\n```python\n# Los tres niveles en un endpoint\n@router.post(\"/orders\")\nasync def create_order(\n    user_cache: UserCache,        # CacheService específico de dominio\n    product_cache: ProductCache,  # Otro cache de dominio\n    redis: RedisClient,           # Cliente raw para ops custom\n):\n    user = await user_cache.get_or_set(user_id, factory=fetch_user)\n    async with redis.pipeline() as pipe:  # Bajar a raw para batch\n        ...\n```\n\nCacheService es genérico sobre modelos Pydantic, así que `CacheService[User]` realmente valida y deserializa datos cacheados de vuelta a instancias de User. El path de serialización verifica si el valor es un BaseModel y llama `model_dump_json()`, de lo contrario hace fallback a encoding JSON estándar. En lectura, si un tipo de modelo está configurado, ejecuta `model_validate_json()` sobre el string cacheado. Esto atrapa drift de schema temprano en lugar de explotar más adelante cuando accedes a un atributo que ya no existe.\n\n```python\nclass CacheService(Generic[T]):\n    def __init__(\n        self,\n        redis: Redis,\n        namespace: str,\n        model: type[T] | None = None,  # Modelo Pydantic opcional\n        default_ttl: int = 300,\n        use_jitter: bool = True,\n        prefix: str = \"cache\",\n        version: str = \"v1\",\n    ): ...\n```\n\nLas keys de cache se generan determinísticamente con resistencia a colisiones. El formato es `{prefix}:{version}:{namespace}:{identifier}` con un hash de params opcional añadido. Cuando pasas parámetros de query a `get_or_set`, se serializan a JSON con keys ordenadas, luego se hashean con SHA256 a 12 caracteres. Esto significa que `get_or_set(\"list\", params={\"page\": 1, \"category\": \"electronics\"})` produce una key estable sin importar el orden del dict. El segmento de versión existe específicamente para invalidación de cache durante deployments.\n\n```python\ndef build_cache_key(\n    namespace: str,\n    identifier: str,\n    params: dict[str, Any] | None = None,\n    prefix: str = \"cache\",\n    version: str = \"v1\",\n) -> str:\n    parts = [prefix, version, namespace, identifier]\n    if params:\n        param_str = json.dumps(params, sort_keys=True)\n        param_hash = hashlib.sha256(param_str.encode()).hexdigest()[:12]\n        parts.append(param_hash)\n    return \":\".join(parts)\n```\n\nEl jitter de TTL está activado por defecto porque las estampidas de cache son un problema real que la mayoría de tutoriales ignoran. Cuando mil requests golpean una key popular expirada simultáneamente, todas fallan el cache y aplastan tu base de datos. La función `get_ttl_with_jitter` añade varianza aleatoria (10% por defecto) para distribuir los tiempos de expiración. Un TTL de 300 segundos se convierte en algo entre 270 y 330 segundos. Combinado con el patrón cache-aside en `get_or_set`, esto previene expiración sincronizada en tus hot keys.\n\n```python\ndef get_ttl_with_jitter(base_ttl: int, jitter_percent: float = 0.1) -> int:\n    jitter = int(base_ttl * jitter_percent)\n    return base_ttl + random.randint(-jitter, jitter)\n```\n\nLa gestión de conexiones usa el connection pool async de redis-py con lógica de retry integrada. La estrategia de retry es `ExponentialWithJitterBackoff` con tope en 10 segundos, manejando ConnectionError, TimeoutError y BusyLoadingError específicamente. La invalidación por patrón usa SCAN en lugar de KEYS porque KEYS bloquea el servidor Redis en keyspaces grandes. El método `invalidate_pattern` itera con `scan_iter` y elimina matches individualmente. Es más lento que un único KEYS + DEL pero no va a congelar tu Redis de producción por 30 segundos.",
  "tech_stack": [
    "Python 3.12",
    "FastAPI",
    "Redis",
    "Pydantic v2",
    "hiredis",
    "redis-py async"
  ],
  "github_url": "https://github.com/CarterPerez-dev/fastapi-rc",
  "demo_url": null,
  "website_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": "https://pypi.org/project/fastapi-rc/",
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": "class CacheService(Generic[T]):\n    \"\"\"\n    Generic caching service for Pydantic models\n    Provides cache-aside pattern with automatic serialization\n    \"\"\"\n    def __init__(\n        self,\n        redis: Redis,\n        namespace: str,\n        model: type[T] | None = None,\n        default_ttl: int = 300,\n        use_jitter: bool = True,\n        prefix: str = \"cache\",\n        version: str = \"v1\",\n    ):\n        self.redis = redis\n        self.namespace = namespace\n        self.model = model\n        self.default_ttl = default_ttl\n        self.use_jitter = use_jitter\n        self.prefix = prefix\n        self.version = version\n\n    async def get_or_set(\n        self,\n        identifier: str,\n        factory: Callable[[], Awaitable[T]],\n        ttl: int | None = None,\n        params: dict[str, Any] | None = None,\n    ) -> T:\n        \"\"\"\n        Cache-aside pattern: get from cache or execute factory and cache result\n        \"\"\"\n        cached = await self.get(identifier, params)\n        if cached is not None:\n            return cached\n\n        value = await factory()\n        await self.set(identifier, value, ttl, params)\n        return value",
  "code_language": "python",
  "code_filename": "https://github.com/CarterPerez-dev/fastapi-rc/blob/main/fastapi_rc/service.py",
  "thumbnail_url": null,
  "banner_url": null,
  "screenshots": null,
  "stars_count": 3,
  "forks_count": null,
  "downloads_count": null,
  "users_count": null,
  "display_order": 0,
  "is_complete": true,
  "is_featured": false,
  "status": "active",
  "start_date": "2025-12-13",
  "end_date": null
}
