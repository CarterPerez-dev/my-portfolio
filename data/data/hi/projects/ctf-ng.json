{
  "slug": "cisa-presidents-cup-ctf",
  "language": "hi",
  "title": "CISA President's Cup CTF Platform",
  "subtitle": "Real-time scoring और multi-container WebSocket coordination के साथ distributed CTF platform backend",
  "description": "CISA के वार्षिक President's Cup cybersecurity competition platform के लिए core backend contributor। Real-time notification system, scoring engine, support ticketing, और codebase में adopt किए गए middleware patterns सहित foundational architecture को design और implement किया। Platform Docker Swarm deployment में distributed Flask containers में concurrent users को handle करता है।",
  "technical_details": "## Distributed Coordination Problem\n\nPlatform load balancer के पीछे multiple Flask containers run करता है। इस setup में standard WebSocket implementations टूट जाते हैं क्योंकि Flask-SocketIO rooms per process in-memory होते हैं। अगर User A Container 1 से connect करता है और User B Container 2 से connect करता है, तो वे rooms के through communicate नहीं कर सकते। हर real-time feature (leaderboard updates, scoring notifications, support ticket replies) को एक solution की जरूरत थी जो container boundaries के across काम करे।\n\n## Coordination Layer के रूप में Redis Pub/Sub\n\nSolution: हर container अपनी lookup table maintain करता है जो user IDs को socket session IDs से map करती है। जब एक notification fire होता है, यह Redis channel में publish करता है। हर container message receive करता है, check करता है \"क्या यह user मुझसे connected है?\", और सिर्फ तभी emit करता है जब उनके पास active connection हो। कोई wasted broadcasts नहीं, कोई cross-container room management नहीं।\n\n```python\ndef _handle_notification_message(self, message):\n    user_ids = message.get('user_ids', [])\n    event_name = message.get('event_name')\n    data = message.get('data')\n\n    for user_id in user_ids:\n        user_sids = get_user_connections(user_id)  # Local lookup only\n        for sid in user_sids:\n            self.socketio.emit(event_name, data, to=sid)\n```\n\n`user_connections` dict per-container है। Redis broadcast handle करता है, हर container अपने users handle करता है। Clean separation।\n\n## Gunicorn Threading Bug\n\nDevelopment में, सब कुछ काम करता था। Production में Gunicorn के gevent workers के साथ, Redis subscriber thread silently die हो जाता था। दो compounding issues: Gunicorn का pre-fork model app initialization के दौरान start होने वाले threads को destroy कर देता है, और gevent की monkey patching timing dev और prod के बीच differ करती है। Fix था `threading.Thread` को `socketio.start_background_task()` से replace करना, जो gevent mode में `gevent.spawn()` को auto-select करता है। छोटा change, खोजने में घंटों की debugging।\n\n## Complexity को Abstract करना\n\nDomain code को Redis या container coordination के बारे में पता नहीं होना चाहिए। `NotificationService` simple methods expose करती है जैसे `broadcast_attempt_update(event_id, team_id, challenge_id)`। Under the hood यह user IDs resolve करती है, Redis में publish करती है, failures को gracefully handle करती है। Scoring controller पर काम करने वाला teammate बस method call करता है और आगे बढ़ जाता है।\n\n```python\n@staticmethod\ndef broadcast_attempt_update(event_id, team_id, challenge_id, question_id):\n    NotificationService._emit_refetch(\n        path=f\"/ng/events/{event_id}/challenges/{challenge_id}\",\n        team_id=team_id\n    )\n    NotificationService._emit_refetch(\n        path=f\"/ng/events/{event_id}/leaderboard\",\n        event_id=event_id\n    )\n```\n\n## Decorator-Based Middleware\n\nहर endpoint को auth, input validation, resource loading, और permission checks चाहिए। हर route handler में वो boilerplate लिखना error-prone और ugly है। जो approach emerge हुआ (team के साथ बहुत सारे PR feedback और iteration के through): composable decorators जो cleanly stack होते हैं।\n\n```python\n@user_endpoint(json_required=True)\n@load_event(LoaderType.PARAM)\n@load_challenge(LoaderType.PARAM)\n@load_question(LoaderType.PARAM)\n@load_team_by_user_and_event()\n@check_permissions(PermissionEnum.CAN_PLAY_CHALLENGES)\ndef post(self, event_id, challenge_id, question_id,\n         event, challenge, question, team, current_user, json_data):\n    return submit_answer(event, challenge, question, team, current_user, json_data)\n```\n\nजब तक handler run होता है, auth verified है, JSON parsed है, सभी models loaded हैं, permissions checked हैं। Handler सिर्फ business logic करता है। यह pattern पूरे backend में फैल गया। Events, teams, tickets, scores के लिए resource loaders। Permission decorators। Ownership validators। सब composable।\n\n## Validation Framework\n\nहर model को consistent error messages के साथ input validation चाहिए। Controllers में scattered ad-hoc checks के बजाय, एक `BaseValidator` है जिसमें chainable methods हैं और एक `@validation_field` decorator है जो common patterns handle करता है (required checks, None handling, friendly error messages)।\n\n```python\nvalidator = BaseValidator()\nvalidator.validate_string(data, \"name\", max_length=64, required=True)\nvalidator.validate_model_id(data, \"event_id\", \"Event\", required=True)\nvalidator.validate_datetime(data, \"expires_at\", allow_past=False)\nreturn validator.validate()  # Returns clean dict or raises ValidationError\n```\n\nSingle pass: validates और parsed data extract करता है। हर model का `validate()` classmethod इसे use करता है। पूरे API में consistent error shape।\n\n## मैंने क्या सीखा\n\nयह पहली बार था जब मैं real team के साथ इस scale पर किसी चीज़ पर काम कर रहा था। Project पर senior devs (particularly जो DevOps, complex Docker Swarm orchestration, challenge parsing, VNC management, और बहुत कुछ handle कर रहे थे) ने मुझे सिखाया कि actually distributed systems के बारे में कैसे सोचना है, सिर्फ features build नहीं करना। Decorator patterns code review feedback से निकले। Validation framework team को actually जो चाहिए था उसके based पर multiple iterations से evolve हुआ। अपने early PRs को later वाले से compare करना, growth embarrassing है लेकिन real है। जो code दूसरे लोगों को maintain करना है उसे ship करना बदल देता है कि आप उसे कैसे लिखते हैं।",
  "tech_stack": ["Python", "Flask", "Flask-SocketIO", "Redis", "PostgreSQL", "SQLAlchemy", "AWS SES", "AWS S3", "CTFd", "Docker Swarm", "pytest", "Nginx"],
  "github_url": "https://github.com/CyberSkyline/ctf-ng",
  "website_url": "https://presidentscup.cisa.gov/",
  "demo_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": null,
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": "@user_endpoint(json_required=True)\n@load_event(LoaderType.PARAM)\n@load_challenge(LoaderType.PARAM)\n@load_question(LoaderType.PARAM)\n@load_team_by_user_and_event()\n@limiter.limit(\"1 per 1 seconds\")\n@check_permissions(PermissionEnum.CAN_PLAY_CHALLENGES, \"You do not have permission to play challenges.\")\ndef post(\n    self,\n    event_id: int,\n    challenge_id: int,\n    question_id: int,\n    event,\n    challenge,\n    question,\n    team,\n    current_user: User,\n    permissions,\n    json_data,\n    **kwargs,\n):\n    result = submit_answer(\n        event=event,\n        challenge=challenge,\n        question=question,\n        team=team,\n        current_user=current_user,\n        submission=json_data.get(\"submission\", \"\"),\n    )\n    return success_response(result, status_code=201)",
  "code_language": "python",
  "code_filename": "https://github.com/CyberSkyline/ctf-ng/blob/development/backend/ng/scoring/routes/user_routes.py",
  "display_order": 0,
  "is_complete": true,
  "is_featured": true,
  "thumbnail_url": null,
  "banner_url": null,
  "screenshots": null,
  "stars_count": 3,
  "forks_count": null,
  "downloads_count": null,
  "users_count": null,
  "status": "active",
  "start_date": "2025-05-01",
  "end_date": null
}
