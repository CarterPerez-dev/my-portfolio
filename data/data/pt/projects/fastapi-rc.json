{
  "slug": "fastapi-rc",
  "language": "pt",
  "title": "fastapi-rc",
  "subtitle": "Caching Redis para FastAPI sem a mágica de decoradores",
  "description": "Uma biblioteca de caching Redis de três camadas para FastAPI que te dá acesso direto ao cliente, um wrapper de serviço genérico, e caches de domínio customizados que integram com a injeção de dependências do FastAPI. Construída para desenvolvedores que querem controle granular sobre comportamento de caching ao invés de decoradores opinados.",
  "technical_details": "A biblioteca é estruturada em torno de três níveis de abstração que você pode misturar livremente. Na base, você obtém o cliente Redis assíncrono puro através do sistema DI do FastAPI. Um nível acima, CacheService envolve padrões comuns como cache-aside, gerenciamento de TTL e serialização. No topo, você define caches tipados por domínio como dependências. Isso permite que você desça para Redis puro para pipelines ou scripts Lua enquanto ainda usa a camada de serviço para 90% das operações.\n\n```python\n# Todos os três níveis em um endpoint\n@router.post(\"/orders\")\nasync def create_order(\n    user_cache: UserCache,        # CacheService específico de domínio\n    product_cache: ProductCache,  # Outro cache de domínio\n    redis: RedisClient,           # Cliente puro para ops customizadas\n):\n    user = await user_cache.get_or_set(user_id, factory=fetch_user)\n    async with redis.pipeline() as pipe:  # Desce para puro para batch\n        ...\n```\n\nCacheService é genérico sobre modelos Pydantic, então `CacheService[User]` realmente valida e desserializa dados cacheados de volta para instâncias User. O caminho de serialização verifica se o valor é um BaseModel e chama `model_dump_json()`, caso contrário cai de volta para codificação JSON padrão. Na leitura, se um tipo de modelo está configurado, executa `model_validate_json()` na string cacheada. Isso pega drift de schema cedo ao invés de explodir downstream quando você acessa um atributo que não existe mais.\n\n```python\nclass CacheService(Generic[T]):\n    def __init__(\n        self,\n        redis: Redis,\n        namespace: str,\n        model: type[T] | None = None,  # Modelo Pydantic opcional\n        default_ttl: int = 300,\n        use_jitter: bool = True,\n        prefix: str = \"cache\",\n        version: str = \"v1\",\n    ): ...\n```\n\nChaves de cache são geradas deterministicamente com resistência a colisões. O formato é `{prefix}:{version}:{namespace}:{identifier}` com um hash de param opcional anexado. Quando você passa parâmetros de query para `get_or_set`, eles são serializados em JSON com chaves ordenadas, depois hasheados SHA256 para 12 caracteres. Isso significa que `get_or_set(\"list\", params={\"page\": 1, \"category\": \"electronics\"})` produz uma chave estável independentemente da ordenação do dict. O segmento version existe especificamente para invalidação de cache durante deployments.\n\n```python\ndef build_cache_key(\n    namespace: str,\n    identifier: str,\n    params: dict[str, Any] | None = None,\n    prefix: str = \"cache\",\n    version: str = \"v1\",\n) -> str:\n    parts = [prefix, version, namespace, identifier]\n    if params:\n        param_str = json.dumps(params, sort_keys=True)\n        param_hash = hashlib.sha256(param_str.encode()).hexdigest()[:12]\n        parts.append(param_hash)\n    return \":\".join(parts)\n```\n\nJitter de TTL está ativo por padrão porque cache stampedes são um problema real que a maioria dos tutoriais ignora. Quando mil requisições atingem uma chave popular expirada simultaneamente, todas falham no cache e esmagam seu banco de dados. A função `get_ttl_with_jitter` adiciona variância aleatória (padrão 10%) para espalhar tempos de expiração. Um TTL de 300 segundos torna-se algo entre 270 e 330 segundos. Combinado com o padrão cache-aside em `get_or_set`, isso previne expiração sincronizada através de suas chaves quentes.\n\n```python\ndef get_ttl_with_jitter(base_ttl: int, jitter_percent: float = 0.1) -> int:\n    jitter = int(base_ttl * jitter_percent)\n    return base_ttl + random.randint(-jitter, jitter)\n```\n\nGerenciamento de conexão usa connection pool assíncrono do redis-py com lógica de retry embutida. A estratégia de retry é `ExponentialWithJitterBackoff` limitada a 10 segundos, lidando com ConnectionError, TimeoutError e BusyLoadingError especificamente. Invalidação de padrão usa SCAN ao invés de KEYS porque KEYS bloqueia o servidor Redis em keyspaces grandes. O método `invalidate_pattern` itera com `scan_iter` e deleta correspondências individualmente. É mais lento que um único KEYS + DEL mas não vai congelar seu Redis de produção por 30 segundos.",
  "tech_stack": [
    "Python 3.12",
    "FastAPI",
    "Redis",
    "Pydantic v2",
    "hiredis",
    "redis-py async"
  ],
  "github_url": "https://github.com/CarterPerez-dev/fastapi-rc",
  "demo_url": null,
  "website_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": "https://pypi.org/project/fastapi-rc/",
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": "class CacheService(Generic[T]):\n    \"\"\"\n    Generic caching service for Pydantic models\n    Provides cache-aside pattern with automatic serialization\n    \"\"\"\n    def __init__(\n        self,\n        redis: Redis,\n        namespace: str,\n        model: type[T] | None = None,\n        default_ttl: int = 300,\n        use_jitter: bool = True,\n        prefix: str = \"cache\",\n        version: str = \"v1\",\n    ):\n        self.redis = redis\n        self.namespace = namespace\n        self.model = model\n        self.default_ttl = default_ttl\n        self.use_jitter = use_jitter\n        self.prefix = prefix\n        self.version = version\n\n    async def get_or_set(\n        self,\n        identifier: str,\n        factory: Callable[[], Awaitable[T]],\n        ttl: int | None = None,\n        params: dict[str, Any] | None = None,\n    ) -> T:\n        \"\"\"\n        Cache-aside pattern: get from cache or execute factory and cache result\n        \"\"\"\n        cached = await self.get(identifier, params)\n        if cached is not None:\n            return cached\n\n        value = await factory()\n        await self.set(identifier, value, ttl, params)\n        return value",
  "code_language": "python",
  "code_filename": "https://github.com/CarterPerez-dev/fastapi-rc/blob/main/fastapi_rc/service.py",
  "thumbnail_url": null,
  "banner_url": null,
  "screenshots": null,
  "stars_count": 3,
  "forks_count": null,
  "downloads_count": null,
  "users_count": null,
  "display_order": 0,
  "is_complete": true,
  "is_featured": false,
  "status": "active",
  "start_date": "2025-12-13",
  "end_date": null
}
