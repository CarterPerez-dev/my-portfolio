{
  "slug": "fastapi-rc",
  "language": "zh",
  "title": "fastapi-rc",
  "subtitle": "没有装饰器魔法的 FastAPI Redis 缓存",
  "description": "一个三层 Redis 缓存库，用于 FastAPI，提供直接的客户端访问、通用服务包装器，以及与 FastAPI 依赖注入集成的自定义域缓存。为那些想要对缓存行为进行精细控制而不是使用有强烈倾向性的装饰器的开发者构建。",
  "technical_details": "该库围绕三个可以自由混合的抽象层构建。在底层，你可以通过 FastAPI 的 DI 系统获得原始的异步 Redis 客户端。上一层，CacheService 包装了常见模式，如 cache-aside、TTL 管理和序列化。在顶层，你可以将类型化的按域缓存定义为依赖项。这让你可以在需要 pipeline 或 Lua 脚本时下沉到原始 Redis，同时仍然在 90% 的操作中使用服务层。\n\n```python\n# 一个端点中的三个层级\n@router.post(\"/orders\")\nasync def create_order(\n    user_cache: UserCache,        # 特定域的 CacheService\n    product_cache: ProductCache,  # 另一个域缓存\n    redis: RedisClient,           # 用于自定义操作的原始客户端\n):\n    user = await user_cache.get_or_set(user_id, factory=fetch_user)\n    async with redis.pipeline() as pipe:  # 下沉到原始层做批处理\n        ...\n```\n\nCacheService 对 Pydantic 模型是泛型的，所以 `CacheService[User]` 实际上会验证并将缓存数据反序列化回 User 实例。序列化路径检查值是否是 BaseModel 并调用 `model_dump_json()`，否则回退到标准 JSON 编码。在读取时，如果配置了模型类型，它会对缓存字符串运行 `model_validate_json()`。这可以在早期捕获 schema 漂移，而不是在下游访问不再存在的属性时崩溃。\n\n```python\nclass CacheService(Generic[T]):\n    def __init__(\n        self,\n        redis: Redis,\n        namespace: str,\n        model: type[T] | None = None,  # 可选的 Pydantic 模型\n        default_ttl: int = 300,\n        use_jitter: bool = True,\n        prefix: str = \"cache\",\n        version: str = \"v1\",\n    ): ...\n```\n\n缓存键以确定性方式生成，具有抗冲突性。格式是 `{prefix}:{version}:{namespace}:{identifier}`，可选地附加参数哈希。当你向 `get_or_set` 传递查询参数时，它们会被 JSON 序列化并排序键，然后 SHA256 哈希到 12 个字符。这意味着 `get_or_set(\"list\", params={\"page\": 1, \"category\": \"electronics\"})` 无论 dict 顺序如何都会产生稳定的键。版本段专门用于部署期间的缓存失效。\n\n```python\ndef build_cache_key(\n    namespace: str,\n    identifier: str,\n    params: dict[str, Any] | None = None,\n    prefix: str = \"cache\",\n    version: str = \"v1\",\n) -> str:\n    parts = [prefix, version, namespace, identifier]\n    if params:\n        param_str = json.dumps(params, sort_keys=True)\n        param_hash = hashlib.sha256(param_str.encode()).hexdigest()[:12]\n        parts.append(param_hash)\n    return \":\".join(parts)\n```\n\nTTL 抖动默认开启，因为缓存踩踏是大多数教程忽略的真实问题。当一千个请求同时命中一个过期的热门键时，它们都会缓存未命中并冲击你的数据库。`get_ttl_with_jitter` 函数添加随机方差（默认 10%）来分散过期时间。300 秒的 TTL 会变成 270 到 330 秒之间的某个值。结合 `get_or_set` 中的 cache-aside 模式，这可以防止热门键的同步过期。\n\n```python\ndef get_ttl_with_jitter(base_ttl: int, jitter_percent: float = 0.1) -> int:\n    jitter = int(base_ttl * jitter_percent)\n    return base_ttl + random.randint(-jitter, jitter)\n```\n\n连接管理使用 redis-py 的异步连接池，内置重试逻辑。重试策略是 `ExponentialWithJitterBackoff`，上限为 10 秒，专门处理 ConnectionError、TimeoutError 和 BusyLoadingError。模式失效使用 SCAN 而不是 KEYS，因为 KEYS 在大型键空间上会阻塞 Redis 服务器。`invalidate_pattern` 方法使用 `scan_iter` 迭代并单独删除匹配项。它比单个 KEYS + DEL 慢，但不会让你的生产 Redis 冻结 30 秒。",
  "tech_stack": [
    "Python 3.12",
    "FastAPI",
    "Redis",
    "Pydantic v2",
    "hiredis",
    "redis-py async"
  ],
  "github_url": "https://github.com/CarterPerez-dev/fastapi-rc",
  "demo_url": null,
  "website_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": "https://pypi.org/project/fastapi-rc/",
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": "class CacheService(Generic[T]):\n    \"\"\"\n    Generic caching service for Pydantic models\n    Provides cache-aside pattern with automatic serialization\n    \"\"\"\n    def __init__(\n        self,\n        redis: Redis,\n        namespace: str,\n        model: type[T] | None = None,\n        default_ttl: int = 300,\n        use_jitter: bool = True,\n        prefix: str = \"cache\",\n        version: str = \"v1\",\n    ):\n        self.redis = redis\n        self.namespace = namespace\n        self.model = model\n        self.default_ttl = default_ttl\n        self.use_jitter = use_jitter\n        self.prefix = prefix\n        self.version = version\n\n    async def get_or_set(\n        self,\n        identifier: str,\n        factory: Callable[[], Awaitable[T]],\n        ttl: int | None = None,\n        params: dict[str, Any] | None = None,\n    ) -> T:\n        \"\"\"\n        Cache-aside pattern: get from cache or execute factory and cache result\n        \"\"\"\n        cached = await self.get(identifier, params)\n        if cached is not None:\n            return cached\n\n        value = await factory()\n        await self.set(identifier, value, ttl, params)\n        return value",
  "code_language": "python",
  "code_filename": "https://github.com/CarterPerez-dev/fastapi-rc/blob/main/fastapi_rc/service.py",
  "thumbnail_url": null,
  "banner_url": null,
  "screenshots": null,
  "stars_count": 3,
  "forks_count": null,
  "downloads_count": null,
  "users_count": null,
  "display_order": 0,
  "is_complete": true,
  "is_featured": false,
  "status": "active",
  "start_date": "2025-12-13",
  "end_date": null
}
