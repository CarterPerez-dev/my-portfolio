{
  "slug": "vuemantics",
  "language": "zh",
  "title": "Vuemantics",
  "subtitle": "使用向量嵌入和多模态 AI 的语义图像搜索",
  "description": "我构建这个是为了真正理解语义搜索是如何工作的，而不仅仅是调用一个 API 然后祈祷它能用。这个想法源于对 Apple Photos 的不满。现在是 2025 年了，如果我搜索「穿黑色夹克的朋友」，它什么有用的都找不到，因为它仍然只是匹配文本元数据。与此同时，我自己却能构建真正的语义搜索？这种差距让人感觉很奇怪。",
  "technical_details": "这个架构将两个 AI 模型串联起来，每个都做它擅长的事情。Gemini Pro 处理视觉，分析上传的图像和视频以生成详细的文本描述（色调、主体、场景、颜色、动作）。然后这些描述被送入 OpenAI 的 text-embedding-3-small，将它们转换为 1536 维向量。向量通过 pgvector 存储在 PostgreSQL 中，相似性搜索通过余弦距离计算完成。\n\n```python\n# 核心管道：视觉模型描述，嵌入模型向量化\ndescription = await self._analyze_image_with_gemini(file_path)\nembedding = await self._generate_embedding(description)\nawait upload.update_analysis(gemini_summary=description, embedding=embedding)\n```\n\n搜索查询经历相同的嵌入过程。你输入「海滩上的日落」，这段文本变成向量，然后 pgvector 在那个 1536 维空间中找到描述向量最接近的图像。数学只是余弦相似度，但当它工作时，结果感觉像魔法。\n\n```python\n# 查询文本变成向量，pgvector 找到最近邻\nquery_embedding = await self._generate_query_embedding(request.query)\nresults = await Upload.search_by_embedding(\n    query_embedding=query_embedding,\n    user_id=user_id,\n    similarity_threshold=request.similarity_threshold\n)\n```\n\n后端使用 FastAPI，完全异步处理。上传立即返回，而后台任务处理 Gemini → OpenAI → pgvector 管道。我选择了原生 asyncpg 而不是 ORM，因为我需要直接控制向量类型编解码器的注册。Redis 处理缓存。前端是 React 配 TypeScript，没什么花哨的，就是功能性的。\n\n```python\n# asyncpg 的自定义向量编解码器 - pgvector 没有原生 Python 支持\nawait conn.set_type_codec(\n    \"vector\",\n    encoder=lambda v: f\"[{','.join(map(str, v))}]\",\n    decoder=lambda v: list(map(float, v[1:-1].split(\",\"))),\n    schema=\"public\",\n)\n```\n\n当前状态：它能工作，但需要阈值校准。有一个 similarity_threshold 参数（默认 0.25）控制匹配的严格程度。太低会得到不相关的结果，太高会错过有效匹配。我把它调到了一个还不错的点，然后就再没回来好好调过。困难的部分已经完成，只剩下参数调整了。\n\n下一步是在我的家用服务器上用本地模型而不是付费 API 来运行。Ollama 现在支持视觉模型（llava、llama3.2-vision、qwen2-vl），可以替代 Gemini 生成描述。对于嵌入，nomic-embed-text 或 mxbai-embed-large 可以本地运行。质量会稍微下降，但对于个人媒体搜索来说足够了，而且这样运行就真的免费了。最终我想在它上面构建一个 iOS 应用。基本上是我自己的私人 iCloud Photos，但真的能找到东西。",
  "tech_stack": [
    "Python",
    "FastAPI",
    "PostgreSQL",
    "pgvector",
    "Redis",
    "React",
    "TypeScript",
    "Vite",
    "Tailwind CSS",
    "OpenAI API",
    "Google Gemini API",
    "Docker",
    "Nginx"
  ],
  "github_url": "https://github.com/CarterPerez-dev/vuemantics",
  "website_url": "https://vuemantics.com",
  "demo_url": null,
  "docs_url": null,
  "blog_url": null,
  "pypi_url": null,
  "npm_url": null,
  "ios_url": null,
  "android_url": null,
  "code_snippet": "async def analyze_media(self, upload_id: UUID) -> None:\n    \"\"\"\n    Analyze media file and generate embeddings.\n    Updates upload record with gemini_summary, embedding, and processing_status.\n    \"\"\"\n    upload = await Upload.find_by_id(upload_id)\n    if not upload:\n        return\n\n    await upload.update_status(ProcessingStatus.ANALYZING)\n\n    # Get description from Gemini (vision model)\n    if upload.file_type == \"image\":\n        description = await self._analyze_image_with_gemini(file_path)\n    else:\n        description = await self._analyze_video_with_gemini(\n            upload.user_id, upload_id, file_path\n        )\n\n    await upload.update_status(ProcessingStatus.EMBEDDING)\n\n    # Convert description to vector embedding (OpenAI)\n    embedding = await self._generate_embedding(description)\n\n    # Store both for search\n    await upload.update_analysis(\n        gemini_summary=description, \n        embedding=embedding\n    )",
  "code_language": "python",
  "code_filename": "https://github.com/CarterPerez-dev/vuemantics/tree/main/backend/services/ai_service.py",
  "thumbnail_url": null,
  "banner_url": null,
  "screenshots": null,
  "stars_count": null,
  "forks_count": null,
  "downloads_count": null,
  "users_count": null,
  "display_order": 0,
  "is_complete": false,
  "is_featured": false,
  "status": "active",
  "start_date": "2025-06-10",
  "end_date": null
}
