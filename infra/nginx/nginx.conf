# =============================================================================
# AngelaMos | 2025
# nginx.conf
# OpenResty configuration with Prometheus metrics
# =============================================================================

worker_processes auto;
worker_rlimit_nofile 65535;

error_log /usr/local/openresty/nginx/logs/error.log warn;
pid /var/run/openresty/nginx.pid;

events {
    worker_connections 4096;
    multi_accept on;
    use epoll;
}

http {
    include /usr/local/openresty/nginx/conf/mime.types;
    default_type application/octet-stream;

    lua_package_path "/usr/local/openresty/site/lualib/?.lua;;";
    lua_shared_dict prometheus_metrics 10M;

    init_worker_by_lua_block {
        prometheus = require("prometheus").init("prometheus_metrics")

        metric_requests = prometheus:counter(
            "nginx_http_requests_total",
            "Number of HTTP requests",
            {"host", "status", "method", "endpoint"})

        metric_latency = prometheus:histogram(
            "nginx_http_request_duration_seconds",
            "HTTP request latency",
            {"host", "method", "endpoint"},
            {0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10})

        metric_bytes_sent = prometheus:counter(
            "nginx_http_response_bytes_total",
            "Total bytes sent to clients",
            {"host", "status"})

        metric_connections = prometheus:gauge(
            "nginx_connections",
            "Number of connections",
            {"state"})
    }

    map $uri $endpoint_group {
        ~^/api/auth      "auth";
        ~^/api/users     "users";
        ~^/api/projects  "projects";
        ~^/api/blogs     "blogs";
        ~^/api/          "api_other";
        ~^/assets/       "static";
        ~^/health        "health";
        ~^/metrics       "metrics";
        default          "frontend";
    }

    log_by_lua_block {
        if ngx.var.uri ~= "/metrics" and ngx.var.uri ~= "/health" then
            metric_requests:inc(1, {ngx.var.host, ngx.var.status, ngx.var.request_method, ngx.var.endpoint_group})
            metric_latency:observe(tonumber(ngx.var.request_time), {ngx.var.host, ngx.var.request_method, ngx.var.endpoint_group})
            metric_bytes_sent:inc(tonumber(ngx.var.bytes_sent), {ngx.var.host, ngx.var.status})
        end
    }

    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }

    upstream backend {
        server backend:8000 max_fails=3 fail_timeout=30s;
        keepalive 32;
        keepalive_requests 1000;
        keepalive_timeout 60s;
    }

    resolver 127.0.0.11 valid=30s ipv6=off;

    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=1r/s;
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;
    limit_req_status 429;

    log_format main_timed '$remote_addr - $remote_user [$time_local] '
                          '"$request" $status $body_bytes_sent '
                          '"$http_referer" "$http_user_agent" '
                          'rt=$request_time uct="$upstream_connect_time" '
                          'uht="$upstream_header_time" urt="$upstream_response_time"';

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens off;

    client_body_buffer_size 128k;
    client_header_buffer_size 16k;
    client_max_body_size 10m;
    large_client_header_buffers 4 16k;

    client_body_timeout 12s;
    client_header_timeout 12s;
    send_timeout 10s;

    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_min_length 256;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    gzip_disable "msie6";

    include /etc/nginx/conf.d/*.conf;
}
